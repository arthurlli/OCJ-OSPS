{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1) need to download modules included below\n",
    "2) install ImagerMagick following the instrution in website of wand.\n",
    "3) install google.cloud.vision -> configurate your credentials and private key for connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: similar code as \"Hand-written_OCR\" using Google Vision API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API reference: https://cloud.google.com/python/docs/reference/vision/latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1) convert PDF to JPG\n",
    "2) call GV API to read data\n",
    "3) output data: i) folder same naming as PDF file, ii) pages stored saparately in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convert PDF to JPG\n",
    "from wand.image import Image as WandImage\n",
    "from PyPDF2 import PdfReader\n",
    "# ML based OCR \n",
    "import pytesseract  \n",
    "from PIL import Image\n",
    "# for progress bar\n",
    "from tqdm import tqdm\n",
    "# other\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, output all files under \"./pdf/STD/\" folder\n",
    "def list_files(directory: str):\n",
    "    \"\"\"\n",
    "    List up all files under a directory\n",
    "    \n",
    "    Input:\n",
    "        directory (str): directory that stores all files to be listed up\n",
    "    \"\"\"\n",
    "    file_list = []\n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Iterate over each file in the current directory\n",
    "        for file in files:\n",
    "            # Get the file names\n",
    "            #file_path = os.path.join(root, file)  #do not need root path\n",
    "            file_path = file\n",
    "            # Append the file path to the list\n",
    "            file_list.append(file_path)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to convert PDF to JPG\n",
    "def pdf_to_images(pdf_path: str, output_folder: str, total_pages: int = None):\n",
    "    \"\"\"\n",
    "    Converting PDF to JPG using WandImage (need to pre-install)\n",
    "    \n",
    "    Input: \n",
    "        pdf_path (str): path that stores all PDF\n",
    "        output_folder (str): folder to store outputs\n",
    "        total_pages (int): number of pages to be proceeded. Default is None, means all page)\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "        # Change to the total number of pages in your PDF\n",
    "        #total_pages = 3\n",
    "        if total_pages is None:\n",
    "            total_pages = len(pdf_reader.pages)\n",
    "        for page_number in tqdm(range(0, total_pages), desc=\"Processing Pages\"):\n",
    "            # Convert each page to an image\n",
    "            with WandImage(filename=f'{pdf_path}[{page_number}]', resolution=400) as img:\n",
    "                # resize the image to ensure high resolution: also resol=300\n",
    "                img.resize(width=2 * img.width, height=2 * img.height)\n",
    "                # Save the image as JPG in the output folder\n",
    "                img.save(filename=os.path.join(output_folder, f'page_{page_number+1}.jpg'))\n",
    "        print(f\"Total page is {total_pages}, so exit the program.\")\n",
    "    return\n",
    "\n",
    "def OCR_image(image_path: str, config: str = None):\n",
    "    \"\"\"\n",
    "    Using pytesseract to OCR image (testing)\n",
    "    \n",
    "    Input: \n",
    "        image_path (str): path that stores image\n",
    "        config (str): configuration for pytesseract\n",
    "    \"\"\"\n",
    "    # OCR on the image\n",
    "    image = Image.open(image_path)\n",
    "    if config is not None:\n",
    "        text = pytesseract.image_to_string(image, lang='jpn', config=config)\n",
    "    else:\n",
    "        # else default\n",
    "        text = pytesseract.image_to_string(image, lang='jpn')\n",
    "    #print(f\"Text:\\n{text}\\n\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions using Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google libraries\n",
    "from google.cloud import vision\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for reading images, returning information in the images \n",
    "def detect_document(path: str, lanHint: str ='ja'):\n",
    "    \"\"\"\n",
    "    Detects document features in an image.\n",
    "    \n",
    "    Input:\n",
    "        path (str): document path\n",
    "    \n",
    "    Output:\n",
    "        image: input image read by vision API\n",
    "        response: Google Vision API response for further processing\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    # add crop hint & language hint (ja) -> looks better\n",
    "    crop_hints_params = vision.CropHintsParams(aspect_ratios=[0.8, 1.0, 1.2])\n",
    "    image_context = vision.ImageContext(crop_hints_params=crop_hints_params, language_hints=[lanHint])\n",
    "    #image_context = vision.ImageContext(crop_hints_params=crop_hints_params) \n",
    "    # if not lan hint, results will be strange\n",
    "    # note: language_hints NOT languageHints becoz it is RPC API (https://github.com/googleapis/google-cloud-python/issues/6387)\n",
    "    response = client.document_text_detection(image=image,image_context=image_context)\n",
    "    #response = client.text_detection(image=image,image_context=image_context)  # use text_detection\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    return image,response\n",
    "\n",
    "\n",
    "def print_response(response):\n",
    "    \"\"\"\n",
    "    Print contents in vision API response to check\n",
    "    \n",
    "    Input:\n",
    "        response: vision API response\n",
    "    \"\"\"\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        print(f\"Current page has {len(page.blocks)} blocks\")\n",
    "        nBlock = 1\n",
    "        for block in page.blocks:\n",
    "            block_text = []\n",
    "            print(\"####################################\")\n",
    "            print(f'Current block: {nBlock}')\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "            for paragraph in block.paragraphs:\n",
    "                paragraph_text = []\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    paragraph_text.append(word_text)\n",
    "                block_text = ''.join(paragraph_text)\n",
    "                print(block_text)\n",
    "                result_str = ''.join(block_text)\n",
    "                print(result_str)\n",
    "            nBlock += 1\n",
    "    return\n",
    "\n",
    "def print_full_text(response):\n",
    "    \"\"\"\n",
    "    Print full content of the response\n",
    "    \n",
    "    Input:\n",
    "        response: vision API response\n",
    "    \"\"\"\n",
    "    print(f\"Full Text: {response.full_text_annotation.text}\")\n",
    "    return\n",
    "\n",
    "# check encoding of the result -> if not Shift-JIS, return False\n",
    "def is_not_encoding(string: str, check: str = 'cp932'):\n",
    "    \"\"\"\n",
    "    To check if the input string is not Shift_JIS\n",
    "    \n",
    "    Input:\n",
    "        string (str): string to be checked\n",
    "        check (str): encoding code page (cp932 is Japanese)\n",
    "    \n",
    "    Output:\n",
    "        boolean\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to decode the string using 'cp932' encoding\n",
    "        decoded_string = string.encode(check)\n",
    "    except UnicodeEncodeError:\n",
    "        # If encoding raises an error, the string is not 'cp932'\n",
    "        return True\n",
    "    else:\n",
    "        # If encoding is successful, the string is 'cp932'\n",
    "        return False\n",
    "\n",
    "def save_full_text(path: str, fn1: str, fn2: str, response):\n",
    "    \"\"\"\n",
    "    Save block by block in vision API response\n",
    "    \n",
    "    Input:\n",
    "        path (str): path to save file\n",
    "        fn1 (str): filename for storing recognized text\n",
    "        fn2 (str): filename for storing confidence of recognized text\n",
    "    \"\"\"\n",
    "    # Open the file in write mode\n",
    "    with open(path+fn1, \"w\") as file:\n",
    "        # Write each element of the list to a new line in the file\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                block_text = []\n",
    "                for paragraph in block.paragraphs:\n",
    "                    paragraph_text = []\n",
    "                    for word in paragraph.words:\n",
    "                        word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                        paragraph_text.append(word_text)\n",
    "                    block_text = ''.join(paragraph_text)\n",
    "                    result_str = ''.join(block_text)\n",
    "                    # testing\n",
    "                    #print(result_str)\n",
    "                    if is_not_encoding(string=result_str):\n",
    "                        print(f\"Wrong encoding: {result_str}\")\n",
    "                    else:\n",
    "                        file.write(f\"{result_str}\\n\")\n",
    "                \n",
    "    with open(path+fn2,\"w\") as file:\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                block_confidence = []\n",
    "                block_confidence.append(block.confidence)\n",
    "                for paragraph in block.paragraphs:\n",
    "                    paragraph_confidence = []\n",
    "                    paragraph_confidence.append(paragraph.confidence)\n",
    "                file.write(f\"{block_confidence}\\n\")\n",
    "    #print(f\"List contents saved to {path+fn1}\")\n",
    "    #print(f\"List confidence saved to {path+fn2}\")\n",
    "    \n",
    "# read all image and save txt (page_x.txt && page_x_confidence.txt) to directory\n",
    "def save_all_full_text(directory_path: str, save_path: str):\n",
    "    \"\"\"\n",
    "    Processing all JPG in directory, call vision API, and then save data.\n",
    "    \n",
    "    Input: \n",
    "        directory_path (str): path that lists all JPGs\n",
    "        save_path (str): path that stores txt\n",
    "    \"\"\"\n",
    "    # Loop over all image files in the directory\n",
    "    for filename in tqdm(os.listdir(directory_path),desc='Processing jpg: '):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # set up image path\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            # detect OCR using vision API\n",
    "            try:\n",
    "                image,response = detect_document(image_path)\n",
    "            except:\n",
    "                print(f\"An execution error encountered at {filename}\")\n",
    "            # then save all OCR text to .txt file with confidence -> remove .jpg from filename\n",
    "            savename = filename.replace('.jpg','')\n",
    "            save_full_text(path=save_path,fn1=f'{savename}.txt',fn2=f'{savename}_confidence.txt',response=response)\n",
    "            # testing\n",
    "            #print_response(response=response)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the key is set up and downloaded, config the environmental variables\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/service_account_PubKey.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config paths\n",
    "input_path = './pdf/STD/'\n",
    "output_path = './jpg/STD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files of STD: ['H19_1月~3月.pdf', 'H19_4月.pdf', 'H19_5月.pdf', 'H19_6月~7月.pdf', 'H19_8月(2).pdf', 'H_198月.pdf']\n",
      "Length: 6\n"
     ]
    }
   ],
   "source": [
    "# show all STD pdf files\n",
    "STD_files = list_files(directory=input_path)\n",
    "print(f\"Files of STD: {STD_files}\")\n",
    "print(f\"Length: {len(STD_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total of 6 folders to process: 1) to JPG, 2) recognise text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceessing PDF (1/6) (note: do not use loop for readibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processing: H19_1月~3月.pdf\n"
     ]
    }
   ],
   "source": [
    "# set paths: save txt file to same folder as jpg\n",
    "fn_0 = STD_files[0]\n",
    "print(f\"File processing: {fn_0}\")\n",
    "folder_0 = fn_0.replace(\".pdf\",\"\")\n",
    "pdf_path = f'./pdf/STD/{fn_0}'\n",
    "jpg_path = f'./jpg/STD/{folder_0}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|████████████████████████████████████████████████████████████████| 78/78 [13:07<00:00, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 78, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert PDF to JPG\n",
    "pdf_to_images(pdf_path=pdf_path, output_folder=jpg_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:   4%|██▊                                                              | 10/235 [00:09<04:08,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LỌLỘLỌLOLOLO101010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing jpg:   6%|███▌                                                             | 13/235 [00:12<03:53,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: CÓ0070GIACỦNH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing jpg:   7%|████▍                                                            | 16/235 [00:14<03:23,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LÒLỒLỘLàLỘLaLỒLỘLỘ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  18%|███████████▉                                                     | 43/235 [00:35<02:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: CÓCÓ10ĐICANH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  22%|██████████████▍                                                  | 52/235 [00:41<02:14,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LỌLỘLỌLO-345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  29%|██████████████████▊                                              | 68/235 [00:50<01:29,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An execution error encountered at page_3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  43%|███████████████████████████▌                                    | 101/235 [01:14<01:28,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LỒLỒLỘLỒLỒLÀLỘLỒLỘ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  45%|████████████████████████████▊                                   | 106/235 [01:18<01:38,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: HƯXẺH*I]:2007/02/1311:24:14測定地点:8M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  50%|████████████████████████████████▏                               | 118/235 [01:27<01:30,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: •\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing jpg:  51%|████████████████████████████████▉                               | 121/235 [01:29<01:27,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: HẠOVLỌCÓECÓ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  57%|████████████████████████████████████▍                           | 134/235 [01:38<01:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: H]RẺH*I]:2007/03/2810:14:45測定地点:8M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing jpg:  58%|█████████████████████████████████████                           | 136/235 [01:41<01:29,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LỄ,L,LỘL,L,Là\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  60%|██████████████████████████████████████▋                         | 142/235 [01:45<01:12,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LLồLỒLỒLÀL,L,L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  63%|████████████████████████████████████████▎                       | 148/235 [01:49<01:04,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LỘLỘLỘLỘLỘLỘLỘLÀ23456789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  71%|█████████████████████████████████████████████▍                  | 167/235 [02:02<00:45,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LOLOLỌLỘLỌLỘLỌLOLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  73%|██████████████████████████████████████████████▊                 | 172/235 [02:07<00:53,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: 測定時刻:2007/01/2213:34:41NÍÞÁ:9M\n",
      "Wrong encoding: LỘLỘLOLỒLLỒLàLàCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  80%|██████████████████████████████████████████████████▉             | 187/235 [02:18<00:35,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: 6760LÀ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing jpg:  81%|███████████████████████████████████████████████████▋            | 190/235 [02:20<00:31,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: LỒLỘLỘLLỒLÀLỒLỘLỘ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing jpg:  82%|████████████████████████████████████████████████████▌           | 193/235 [02:22<00:28,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: 測定時刻:2007/01/16NËŁA:8M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  86%|███████████████████████████████████████████████████████         | 202/235 [02:28<00:27,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: □N3+10201∞@OHNMLOCOMØ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  92%|███████████████████████████████████████████████████████████     | 217/235 [02:40<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: 測定時刻:2007/01/1110:31:14HURẺPHIẢ:8M\n",
      "Wrong encoding: LỌLỘLỌLLỌLOLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:  95%|████████████████████████████████████████████████████████████▋   | 223/235 [02:44<00:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong encoding: HƯRẺU*I]:2007/01/1010:36:14測定地点:8M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|████████████████████████████████████████████████████████████████| 235/235 [02:50<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all fn_0\n",
    "save_all_full_text(directory_path=jpg_path,save_path=jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing PDF (2/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processing: H19_4月.pdf\n"
     ]
    }
   ],
   "source": [
    "# set paths: save txt file to same folder as jpg\n",
    "fn_1 = STD_files[1]\n",
    "print(f\"File processing: {fn_1}\")\n",
    "folder_1 = fn_1.replace(\".pdf\",\"\")\n",
    "pdf_path = f'./pdf/STD/{fn_1}'\n",
    "jpg_path = f'./jpg/STD/{folder_1}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|████████████████████████████████████████████████████████████████| 45/45 [13:34<00:00, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 45, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert PDF to JPG\n",
    "pdf_to_images(pdf_path=pdf_path, output_folder=jpg_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg:   0%|                                                                           | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An execution error encountered at page_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'response' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5eec98be8c80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# OCR all images and return txt files: processing all fn_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msave_all_full_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjpg_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjpg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-6252f8df77d4>\u001b[0m in \u001b[0;36msave_all_full_text\u001b[1;34m(directory_path, save_path)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;31m# then save all OCR text to .txt file with confidence -> remove .jpg from filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0msavename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0msave_full_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'{savename}.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'{savename}_confidence.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[1;31m# testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;31m#print_response(response=response)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'response' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all fn_0\n",
    "save_all_full_text(directory_path=jpg_path,save_path=jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing PDF (3/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths: save txt file to same folder as jpg\n",
    "fn_2 = STD_files[2]\n",
    "print(f\"File processing: {fn_2}\")\n",
    "folder_2 = fn_2.replace(\".pdf\",\"\")\n",
    "pdf_path = f'./pdf/STD/{fn_2}'\n",
    "jpg_path = f'./jpg/STD/{folder_2}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDF to JPG\n",
    "pdf_to_images(pdf_path=pdf_path, output_folder=jpg_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR all images and return txt files: processing all fn_0\n",
    "save_all_full_text(directory_path=jpg_path,save_path=jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing PDF (4/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths: save txt file to same folder as jpg\n",
    "fn_3 = STD_files[3]\n",
    "print(f\"File processing: {fn_3}\")\n",
    "folder_3 = fn_3.replace(\".pdf\",\"\")\n",
    "pdf_path = f'./pdf/STD/{fn_3}'\n",
    "jpg_path = f'./jpg/STD/{folder_3}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDF to JPG\n",
    "pdf_to_images(pdf_path=pdf_path, output_folder=jpg_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR all images and return txt files: processing all fn_0\n",
    "save_all_full_text(directory_path=jpg_path,save_path=jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing PDF (5/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths: save txt file to same folder as jpg\n",
    "fn_4 = STD_files[4]\n",
    "print(f\"File processing: {fn_1}\")\n",
    "folder_4 = fn_4.replace(\".pdf\",\"\")\n",
    "pdf_path = f'./pdf/STD/{fn_4}'\n",
    "jpg_path = f'./jpg/STD/{folder_4}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDF to JPG\n",
    "pdf_to_images(pdf_path=pdf_path, output_folder=jpg_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR all images and return txt files: processing all fn_0\n",
    "save_all_full_text(directory_path=jpg_path,save_path=jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing PDF (6/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths: save txt file to same folder as jpg\n",
    "fn_5 = STD_files[5]\n",
    "print(f\"File processing: {fn_5}\")\n",
    "folder_5 = fn_5.replace(\".pdf\",\"\")\n",
    "pdf_path = f'./pdf/STD/{fn_5}'\n",
    "jpg_path = f'./jpg/STD/{folder_5}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDF to JPG\n",
    "pdf_to_images(pdf_path=pdf_path, output_folder=jpg_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR all images and return txt files: processing all fn_0\n",
    "save_all_full_text(directory_path=jpg_path,save_path=jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing page_22, page_23\n",
    "#testing_path = f'./jpg/STD/testing/'\n",
    "#save_all_full_text(directory_path=testing_path,save_path=testing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
