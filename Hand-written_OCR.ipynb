{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - 1) iterate PDF and convert to JPG (done, 20231129)\n",
    "    - 2) recognize text from JPG using TesseractOCR (!, low accuracy)\n",
    "        - refine recognition: train ML model (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1) need to download modules included below\n",
    "2) install ImagerMagick following the instrution in website of wand.\n",
    "3) install google.cloud.vision -> configurate your credentials and private key for connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convert PDF to JPG\n",
    "from wand.image import Image as WandImage\n",
    "from PyPDF2 import PdfReader\n",
    "# ML based OCR \n",
    "import pytesseract  \n",
    "from PIL import Image\n",
    "# for progress bar\n",
    "from tqdm import tqdm\n",
    "# other\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config paths\n",
    "input_path = './pdf/'\n",
    "output_path = './jpg/'\n",
    "fn = \"平成30年ー平成31年度船舶使用願.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfToImages(pdf_path, output_folder, total_pages=None):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "        # Change to the total number of pages in your PDF\n",
    "        #total_pages = 3\n",
    "        if total_pages is None:\n",
    "            total_pages = len(pdf_reader.pages)\n",
    "        for page_number in tqdm(range(0, total_pages), desc=\"Processing Pages\"):\n",
    "            # Convert each page to an image\n",
    "            with WandImage(filename=f'{pdf_path}[{page_number}]', resolution=400) as img:\n",
    "                # resize the image to ensure high resolution: also resol=300\n",
    "                img.resize(width=2 * img.width, height=2 * img.height)\n",
    "                # Save the image as JPG in the output folder\n",
    "                img.save(filename=os.path.join(output_folder, f'page_{page_number+1}.jpg'))\n",
    "        print(f\"Total page is {total_pages}, so exit the program.\")\n",
    "    return\n",
    "\n",
    "def OCRImage(image_path, config=None):\n",
    "    # OCR on the image\n",
    "    image = Image.open(image_path)\n",
    "    if config is not None:\n",
    "        text = pytesseract.image_to_string(image, lang='jpn', config=config)\n",
    "    else:\n",
    "        # else default\n",
    "        text = pytesseract.image_to_string(image, lang='jpn')\n",
    "    #print(f\"Text:\\n{text}\\n\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 3/3 [00:20<00:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 3, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading pdf and converting to jpg: testing 3 cases first\n",
    "pdfToImages(pdf_path=input_path+fn, output_folder=output_path, total_pages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 228/228 [32:17<00:00,  8.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 228, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading pdf and converting to jpg: try all pages -> takes >30 mins\n",
    "pdfToImages(pdf_path=input_path+fn, output_folder=output_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read text from img: testing page 1 which is PC typed\n",
    "#text = OCRImage(image_path='./jpg/page_1.jpg')\n",
    "# note: make sure jpn.traineddata is downloaded and placed to Tesseract-OCR/tessdata/ folder.\n",
    "#    -  jpn.traineddata: it is downloaded from GitHub as a pre-trained JPN data (users can train their own dataset).\n",
    "# note: TESSDATA_PREFIX should direct to location of tessdata (just in case)\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read text from img: testing page 2 & 3 which is hand written\n",
    "#text = OCRImage(image_path='./jpg/page_2.jpg', config='--psm 11 --oem 3')\n",
    "# note: changing resolution (300 -> 400) can affect the results\n",
    "# --psm N: N from 0 to 13, psm configurates structure of img\n",
    "# --oem N: N from 0 to 3, oem congifurates OCR engine mode\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from img: testing page 2 & 3 which is hand written\n",
    "#text = OCRImage(image_path='./jpg/page_3.jpg')\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use google cloud vision API below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google libraries\n",
    "from google.cloud import vision\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code \n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    return image,response\n",
    "\n",
    "\n",
    "def print_response(response):\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        print(f\"Current page has {len(page.blocks)} blocks\")\n",
    "        nBlock = 1\n",
    "        for block in page.blocks:\n",
    "            block_text = []\n",
    "            print(\"####################################\")\n",
    "            print(f'Current block: {nBlock}')\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "            for paragraph in block.paragraphs:\n",
    "                paragraph_text = []\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    paragraph_text.append(word_text)\n",
    "                block_text = ''.join(paragraph_text)\n",
    "                print(block_text)\n",
    "                result_str = ''.join(block_text)\n",
    "                print(result_str)\n",
    "            nBlock += 1\n",
    "    return\n",
    "\n",
    "def print_full_text(response):\n",
    "    print(f\"Full Text: {response.full_text_annotation.text}\")\n",
    "    return\n",
    "\n",
    "def save_full_text(path, fn1, fn2, response):\n",
    "    # Open the file in write mode\n",
    "    with open(path+fn1, \"w\") as file:\n",
    "        # Write each element of the list to a new line in the file\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                block_text = []\n",
    "                for paragraph in block.paragraphs:\n",
    "                    paragraph_text = []\n",
    "                    for word in paragraph.words:\n",
    "                        word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                        paragraph_text.append(word_text)\n",
    "                    block_text = ''.join(paragraph_text)\n",
    "                    result_str = ''.join(block_text)\n",
    "                file.write(f\"{result_str}\\n\")\n",
    "                \n",
    "    with open(path+fn2,\"w\") as file:\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                block_confidence = []\n",
    "                block_confidence.append(block.confidence)\n",
    "                for paragraph in block.paragraphs:\n",
    "                    paragraph_confidence = []\n",
    "                    paragraph_confidence.append(paragraph.confidence)\n",
    "                file.write(f\"{block_confidence}\\n\")\n",
    "    #print(f\"List contents saved to {path+fn1}\")\n",
    "    #print(f\"List confidence saved to {path+fn2}\")\n",
    "    \n",
    "# read all image and save txt (page_x.txt && page_x_confidence.txt) to directory\n",
    "def save_all_full_text(directory_path,save_path):\n",
    "    # Loop over all image files in the directory\n",
    "    for filename in tqdm(os.listdir(directory_path),desc='Processing jpg: '):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # set up image path\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            # detect OCR using vision API\n",
    "            image,response = detect_document(image_path)\n",
    "            # then save all OCR text to .txt file with confidence -> remove .jpg from filename\n",
    "            savename = filename.replace('.jpg','')\n",
    "            save_full_text(path=save_path,fn1=f'{savename}.txt',fn2=f'{savename}_confidence.txt',response=response)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the key is set up and downloaded, config the environmental variables\n",
    "#os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/service_account_PubKey.json'\n",
    "# set paths: testing with 5 cases\n",
    "jpg_path = './jpg/'\n",
    "testing_path = './jpg/testing/'\n",
    "H30_H31_path = './jpg/平成30年ー平成31年度船舶使用願/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing one: page 2 handwritten\n",
    "image, response = detect_document(path=testing_path+'page_2.jpg')\n",
    "#print_response(response=response)\n",
    "#print_full_text(response=response)\n",
    "save_full_text(path=testing_path,fn1='page_2.txt',fn2='page_2_confidence.txt',response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing testing files\n",
    "save_all_full_text(directory_path=testing_path,save_path=testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 362/362 [07:26<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for H30-H31 files\n",
    "save_all_full_text(directory_path=H30_H31_path,save_path=H30_H31_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages:   0%|          | 0/171 [00:00<?, ?it/s]Processing Pages: 100%|██████████| 171/171 [22:06<00:00,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 171, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和元年 #################\n",
    "R1_pdf_path = './pdf/令和元年船舶使用願.pdf'\n",
    "R1_jpg_path = './jpg/令和元年船舶使用願/'\n",
    "pdfToImages(pdf_path=R1_pdf_path,output_folder=R1_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 171/171 [05:45<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R1 files\n",
    "save_all_full_text(directory_path=R1_jpg_path,save_path=R1_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 166/166 [17:32<00:00,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 166, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和2年 #################\n",
    "R2_pdf_path = './pdf/令和2年度船舶使用願.pdf'\n",
    "R2_jpg_path = './jpg/令和2年度船舶使用願/'\n",
    "pdfToImages(pdf_path=R2_pdf_path,output_folder=R2_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 166/166 [05:29<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R2 files\n",
    "save_all_full_text(directory_path=R2_jpg_path,save_path=R2_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 168/168 [16:47<00:00,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 168, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和3年 #################\n",
    "R3_pdf_path = './pdf/令和3年度船舶使用願.pdf'\n",
    "R3_jpg_path = './jpg/令和3年度船舶使用願/'\n",
    "pdfToImages(pdf_path=R3_pdf_path,output_folder=R3_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 168/168 [05:22<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R3 files\n",
    "save_all_full_text(directory_path=R3_jpg_path,save_path=R3_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 143/143 [11:27<00:00,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 143, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和4年 #################\n",
    "R4_pdf_path = './pdf/令和4年度船舶使用願.pdf'\n",
    "R4_jpg_path = './jpg/令和4年度船舶使用願/'\n",
    "pdfToImages(pdf_path=R4_pdf_path,output_folder=R4_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 143/143 [04:28<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R4 files\n",
    "save_all_full_text(directory_path=R4_jpg_path,save_path=R4_jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: change to txt I/O and reorganize in below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_directory(directory_path, output_text_excel_path, output_confidence_excel_path):\n",
    "    # Create empty DataFrames to store text and confidence results\n",
    "    text_df = pd.DataFrame()\n",
    "    confidence_df = pd.DataFrame()\n",
    "\n",
    "    # Loop over all image files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing image: {image_path}\")\n",
    "\n",
    "            # Detect document features in the image\n",
    "            try:\n",
    "                image,image_results = detect_document(image_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            # Extract information from the results and add to the DataFrames\n",
    "            text_list = []\n",
    "            confidence_list = []\n",
    "            row_final = []\n",
    "\n",
    "            for page in image_results.full_text_annotation.pages:\n",
    "                for block in page.blocks:\n",
    "                    for paragraph in block.paragraphs:\n",
    "                        paragraph_text = []\n",
    "                        #print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "                        for word in paragraph.words:\n",
    "                            word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                            paragraph_text.append(word_text)\n",
    "                        confidence_list.append(paragraph.confidence)\n",
    "                        result_str = ''.join(paragraph_text)\n",
    "                        \n",
    "                        if \"所属\" in result_str:\n",
    "                            print(result_str)\n",
    "                        check_append_content(content=result_str, check=\"平成\",output=row_final)\n",
    "                        check_append_content(content=result_str, check=\"グランメーユ\",output=row_final)\n",
    "                        check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        #check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        #check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        #check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        text_list.append(result_str)\n",
    "\n",
    "            #text_df[filename] = text_list\n",
    "            #confidence_df[filename] = confidence_list\n",
    "            #print(row_final)\n",
    "\n",
    "    # Save the DataFrames to Excel files\n",
    "    #text_df.to_excel(output_text_excel_path, index=False)\n",
    "    #confidence_df.to_excel(output_confidence_excel_path, index=False)\n",
    "\n",
    "    print(f\"Text results saved to {output_text_excel_path}\")\n",
    "    print(f\"Confidence results saved to {output_confidence_excel_path}\")\n",
    "    return\n",
    "\n",
    "def check_append_content(content, check, output, check2=None):\n",
    "    if check in content:\n",
    "        return output.append(content)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images_in_directory(directory_path=jpg_path, output_text_excel_path=\"./\", output_confidence_excel_path=\"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
