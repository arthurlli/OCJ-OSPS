{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - 1) iterate PDF and convert to JPG (done, 20231129)\n",
    "    - 2) recognize text from JPG using TesseractOCR (!, low accuracy)\n",
    "        - refine recognition: train ML model (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convert PDF to JPG\n",
    "from wand.image import Image as WandImage\n",
    "from PyPDF2 import PdfReader\n",
    "# ML based OCR \n",
    "import pytesseract  \n",
    "from PIL import Image\n",
    "# for progress bar\n",
    "from tqdm import tqdm\n",
    "# other\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config paths\n",
    "input_path = './pdf/'\n",
    "output_path = './jpg/'\n",
    "fn = \"平成30年ー平成31年度船舶使用願.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfToImages(pdf_path, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "        # Change to the total number of pages in your PDF\n",
    "        total_pages = 3\n",
    "        for page_number in tqdm(range(0, total_pages), desc=\"Processing Pages\"):\n",
    "            # Convert each page to an image\n",
    "            with WandImage(filename=f'{pdf_path}[{page_number}]', resolution=400) as img:\n",
    "                # resize the image to ensure high resolution: also resol=300\n",
    "                img.resize(width=2 * img.width, height=2 * img.height)\n",
    "                # Save the image as JPG in the output folder\n",
    "                img.save(filename=os.path.join(output_folder, f'page_{page_number+1}.jpg'))\n",
    "        print(f\"Total page is {total_pages}, so exit the program.\")\n",
    "    return\n",
    "\n",
    "def OCRImage(image_path, config=None):\n",
    "    # OCR on the image\n",
    "    image = Image.open(image_path)\n",
    "    if config is not None:\n",
    "        text = pytesseract.image_to_string(image, lang='jpn', config=config)\n",
    "    else:\n",
    "        # else default\n",
    "        text = pytesseract.image_to_string(image, lang='jpn')\n",
    "    #print(f\"Text:\\n{text}\\n\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:28<00:00,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 3, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading pdf and converting to jpg: testing 3 cases first\n",
    "pdfToImages(pdf_path=input_path+fn, output_folder=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read text from img: testing page 1 which is PC typed\n",
    "text = OCRImage(image_path='./jpg/page_1.jpg')\n",
    "# note: make sure jpn.traineddata is downloaded and placed to Tesseract-OCR/tessdata/ folder.\n",
    "#    -  jpn.traineddata: it is downloaded from GitHub as a pre-trained JPN data (users can train their own dataset).\n",
    "# note: TESSDATA_PREFIX should direct to location of tessdata (just in case)\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read text from img: testing page 2 & 3 which is hand written\n",
    "text = OCRImage(image_path='./jpg/page_2.jpg', config='--psm 11 --oem 3')\n",
    "# note: changing resolution (300 -> 400) can affect the results\n",
    "# --psm N: N from 0 to 13, psm configurates structure of img\n",
    "# --oem N: N from 0 to 3, oem congifurates OCR engine mode\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from img: testing page 2 & 3 which is hand written\n",
    "text = OCRImage(image_path='./jpg/page_3.jpg')\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps\n",
    "# 1) use Google Cloud OCR or Azure OCR: AI-based recognition API\n",
    "# GC-OCR: https://cloud.google.com/vision/docs/ocr\n",
    "# 2) trained my own JPN dataset\n",
    "# 3) fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d506ee277728>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "# TODO: google cloud CLI configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code \n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    print(\n",
    "                        \"Word text: {} (confidence: {})\".format(\n",
    "                            word_text, word.confidence\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print(\n",
    "                            \"\\tSymbol: {} (confidence: {})\".format(\n",
    "                                symbol.text, symbol.confidence\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
