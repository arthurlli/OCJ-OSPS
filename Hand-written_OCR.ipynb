{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - 1) iterate PDF and convert to JPG (done, 20231129)\n",
    "    - 2) recognize text from JPG using TesseractOCR (!, low accuracy)\n",
    "        - refine recognition: train ML model (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: retrieving information from scanned hand-written PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1) need to download modules included below\n",
    "2) install ImagerMagick following the instrution in website of wand.\n",
    "3) install google.cloud.vision -> configurate your credentials and private key for connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convert PDF to JPG\n",
    "from wand.image import Image as WandImage\n",
    "from PyPDF2 import PdfReader\n",
    "# ML based OCR \n",
    "import pytesseract  \n",
    "from PIL import Image\n",
    "# for progress bar\n",
    "from tqdm import tqdm\n",
    "# other\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config paths\n",
    "input_path = './pdf/'\n",
    "output_path = './jpg/'\n",
    "fn = \"平成30年ー平成31年度船舶使用願.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder, total_pages=None):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "        # Change to the total number of pages in your PDF\n",
    "        #total_pages = 3\n",
    "        if total_pages is None:\n",
    "            total_pages = len(pdf_reader.pages)\n",
    "        for page_number in tqdm(range(0, total_pages), desc=\"Processing Pages\"):\n",
    "            # Convert each page to an image\n",
    "            with WandImage(filename=f'{pdf_path}[{page_number}]', resolution=400) as img:\n",
    "                # resize the image to ensure high resolution: also resol=300\n",
    "                img.resize(width=2 * img.width, height=2 * img.height)\n",
    "                # Save the image as JPG in the output folder\n",
    "                img.save(filename=os.path.join(output_folder, f'page_{page_number+1}.jpg'))\n",
    "        print(f\"Total page is {total_pages}, so exit the program.\")\n",
    "    return\n",
    "\n",
    "def OCR_image(image_path, config=None):\n",
    "    # OCR on the image\n",
    "    image = Image.open(image_path)\n",
    "    if config is not None:\n",
    "        text = pytesseract.image_to_string(image, lang='jpn', config=config)\n",
    "    else:\n",
    "        # else default\n",
    "        text = pytesseract.image_to_string(image, lang='jpn')\n",
    "    #print(f\"Text:\\n{text}\\n\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 3/3 [00:20<00:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 3, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading pdf and converting to jpg: testing 3 cases first\n",
    "pdf_to_images(pdf_path=input_path+fn, output_folder=output_path, total_pages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 228/228 [32:17<00:00,  8.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 228, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading pdf and converting to jpg: try all pages -> takes >30 mins\n",
    "pdf_to_images(pdf_path=input_path+fn, output_folder=output_path, total_pages=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read text from img: testing page 1 which is PC typed\n",
    "#text = OCR_image(image_path='./jpg/page_1.jpg')\n",
    "# note: make sure jpn.traineddata is downloaded and placed to Tesseract-OCR/tessdata/ folder.\n",
    "#    -  jpn.traineddata: it is downloaded from GitHub as a pre-trained JPN data (users can train their own dataset).\n",
    "# note: TESSDATA_PREFIX should direct to location of tessdata (just in case)\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read text from img: testing page 2 & 3 which is hand written\n",
    "#text = OCR_image(image_path='./jpg/page_2.jpg', config='--psm 11 --oem 3')\n",
    "# note: changing resolution (300 -> 400) can affect the results\n",
    "# --psm N: N from 0 to 13, psm configurates structure of img\n",
    "# --oem N: N from 0 to 3, oem congifurates OCR engine mode\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from img: testing page 2 & 3 which is hand written\n",
    "#text = OCR_image(image_path='./jpg/page_3.jpg')\n",
    "###############################################################################\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use google cloud vision API below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google libraries\n",
    "from google.cloud import vision\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_document(path: str):\n",
    "    \"\"\"\n",
    "    Detects document features in an image.\n",
    "    \n",
    "    Input:\n",
    "        path (str): document path\n",
    "    \n",
    "    Output:\n",
    "        image: input image read by vision API\n",
    "        response: Google Vision API response for further processing\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    return image,response\n",
    "\n",
    "\n",
    "def print_response(response):\n",
    "    \"\"\"\n",
    "    Print contents in vision API response to check\n",
    "    \n",
    "    Input:\n",
    "        response: vision API response\n",
    "    \"\"\"\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        print(f\"Current page has {len(page.blocks)} blocks\")\n",
    "        nBlock = 1\n",
    "        for block in page.blocks:\n",
    "            block_text = []\n",
    "            print(\"####################################\")\n",
    "            print(f'Current block: {nBlock}')\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "            for paragraph in block.paragraphs:\n",
    "                paragraph_text = []\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    paragraph_text.append(word_text)\n",
    "                block_text = ''.join(paragraph_text)\n",
    "                print(block_text)\n",
    "                result_str = ''.join(block_text)\n",
    "                print(result_str)\n",
    "            nBlock += 1\n",
    "    return\n",
    "\n",
    "def print_full_text(response):\n",
    "    \"\"\"\n",
    "    Print full content of the response\n",
    "    \n",
    "    Input:\n",
    "        response: vision API response\n",
    "    \"\"\"\n",
    "    print(f\"Full Text: {response.full_text_annotation.text}\")\n",
    "    return\n",
    "\n",
    "def save_full_text(path: str, fn1: str, fn2: str, response):\n",
    "    \"\"\"\n",
    "    Save block by block in vision API response\n",
    "    \n",
    "    Input:\n",
    "        path (str): path to save file\n",
    "        fn1 (str): filename for storing recognized text\n",
    "        fn2 (str): filename for storing confidence of recognized text\n",
    "    \"\"\"\n",
    "    # Open the file in write mode\n",
    "    with open(path+fn1, \"w\") as file:\n",
    "        # Write each element of the list to a new line in the file\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                block_text = []\n",
    "                for paragraph in block.paragraphs:\n",
    "                    paragraph_text = []\n",
    "                    for word in paragraph.words:\n",
    "                        word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                        paragraph_text.append(word_text)\n",
    "                    block_text = ''.join(paragraph_text)\n",
    "                    result_str = ''.join(block_text)\n",
    "                file.write(f\"{result_str}\\n\")\n",
    "                \n",
    "    with open(path+fn2,\"w\") as file:\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "                block_confidence = []\n",
    "                block_confidence.append(block.confidence)\n",
    "                for paragraph in block.paragraphs:\n",
    "                    paragraph_confidence = []\n",
    "                    paragraph_confidence.append(paragraph.confidence)\n",
    "                file.write(f\"{block_confidence}\\n\")\n",
    "    #print(f\"List contents saved to {path+fn1}\")\n",
    "    #print(f\"List confidence saved to {path+fn2}\")\n",
    "    \n",
    "# read all image and save txt (page_x.txt && page_x_confidence.txt) to directory\n",
    "def save_all_full_text(directory_path: str, save_path: str):\n",
    "    \"\"\"\n",
    "    Processing all JPG in directory, call vision API, and then save data.\n",
    "    \n",
    "    Input: \n",
    "        directory_path (str): path that lists all JPGs\n",
    "        save_path (str): path that stores txt\n",
    "    \"\"\"\n",
    "    # Loop over all image files in the directory\n",
    "    for filename in tqdm(os.listdir(directory_path),desc='Processing jpg: '):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # set up image path\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            # detect OCR using vision API\n",
    "            image,response = detect_document(image_path)\n",
    "            # then save all OCR text to .txt file with confidence -> remove .jpg from filename\n",
    "            savename = filename.replace('.jpg','')\n",
    "            save_full_text(path=save_path,fn1=f'{savename}.txt',fn2=f'{savename}_confidence.txt',response=response)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the key is set up and downloaded, config the environmental variables\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/ccsruser/anaconda3/envs/AORI-OSPS/service_account_PubKey.json'\n",
    "# NOTE: becareful of security!!\n",
    "\n",
    "#os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/service_account_PubKey.json'\n",
    "# set paths: testing with 5 cases\n",
    "jpg_path = './jpg/'\n",
    "testing_path = './jpg/testing/'\n",
    "H30_H31_path = './jpg/平成30年ー平成31年度船舶使用願/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing one: page 2 handwritten\n",
    "image, response = detect_document(path=testing_path+'page_2.jpg')\n",
    "#print_response(response=response)\n",
    "#print_full_text(response=response)\n",
    "save_full_text(path=testing_path,fn1='page_2.txt',fn2='page_2_confidence.txt',response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing testing files\n",
    "save_all_full_text(directory_path=testing_path,save_path=testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 362/362 [07:26<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for H30-H31 files\n",
    "save_all_full_text(directory_path=H30_H31_path,save_path=H30_H31_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages:   0%|          | 0/171 [00:00<?, ?it/s]Processing Pages: 100%|██████████| 171/171 [22:06<00:00,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 171, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和元年 #################\n",
    "R1_pdf_path = './pdf/令和元年船舶使用願.pdf'\n",
    "R1_jpg_path = './jpg/令和元年船舶使用願/'\n",
    "pdf_to_images(pdf_path=R1_pdf_path,output_folder=R1_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 171/171 [05:45<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R1 files\n",
    "save_all_full_text(directory_path=R1_jpg_path,save_path=R1_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 166/166 [17:32<00:00,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 166, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和2年 #################\n",
    "R2_pdf_path = './pdf/令和2年度船舶使用願.pdf'\n",
    "R2_jpg_path = './jpg/令和2年度船舶使用願/'\n",
    "pdf_to_images(pdf_path=R2_pdf_path,output_folder=R2_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 166/166 [05:29<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R2 files\n",
    "save_all_full_text(directory_path=R2_jpg_path,save_path=R2_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 168/168 [16:47<00:00,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 168, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和3年 #################\n",
    "R3_pdf_path = './pdf/令和3年度船舶使用願.pdf'\n",
    "R3_jpg_path = './jpg/令和3年度船舶使用願/'\n",
    "pdf_to_images(pdf_path=R3_pdf_path,output_folder=R3_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 168/168 [05:22<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R3 files\n",
    "save_all_full_text(directory_path=R3_jpg_path,save_path=R3_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 143/143 [11:27<00:00,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page is 143, so exit the program.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############ Convert 令和4年 #################\n",
    "R4_pdf_path = './pdf/令和4年度船舶使用願.pdf'\n",
    "R4_jpg_path = './jpg/令和4年度船舶使用願/'\n",
    "pdf_to_images(pdf_path=R4_pdf_path,output_folder=R4_jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jpg: 100%|██████████| 143/143 [04:28<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# OCR all images and return txt files: processing all for R4 files\n",
    "save_all_full_text(directory_path=R4_jpg_path,save_path=R4_jpg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: retrieving information from all JPGs in directory and save outputs with confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_directory(directory_path: str, output_text_excel_path: str, \n",
    "                                output_confidence_excel_path: str):\n",
    "    \"\"\"\n",
    "    Recognize data in images and store to txt files\n",
    "    \n",
    "    Input:\n",
    "        directory_path (str): path that stores images\n",
    "        output_text_excel_path (str): path to store OCR output\n",
    "        output_confidence_excel_path (str): path to store confidence of OCR\n",
    "    \"\"\"\n",
    "    # Create empty DataFrames to store text and confidence results\n",
    "    text_df = pd.DataFrame()\n",
    "    confidence_df = pd.DataFrame()\n",
    "\n",
    "    # Loop over all image files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing image: {image_path}\")\n",
    "\n",
    "            # Detect document features in the image\n",
    "            try:\n",
    "                image,image_results = detect_document(image_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            # Extract information from the results and add to the DataFrames\n",
    "            text_list = []\n",
    "            confidence_list = []\n",
    "            row_final = []\n",
    "\n",
    "            for page in image_results.full_text_annotation.pages:\n",
    "                for block in page.blocks:\n",
    "                    for paragraph in block.paragraphs:\n",
    "                        paragraph_text = []\n",
    "                        #print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "                        for word in paragraph.words:\n",
    "                            word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                            paragraph_text.append(word_text)\n",
    "                        confidence_list.append(paragraph.confidence)\n",
    "                        result_str = ''.join(paragraph_text)\n",
    "                        \n",
    "                        if \"所属\" in result_str:\n",
    "                            print(result_str)\n",
    "                        check_append_content(content=result_str, check=\"平成\",output=row_final)\n",
    "                        check_append_content(content=result_str, check=\"グランメーユ\",output=row_final)\n",
    "                        check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        #check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        #check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        #check_append_content(content=result_str, check=\"所属\",output=row_final)\n",
    "                        text_list.append(result_str)\n",
    "\n",
    "            #text_df[filename] = text_list\n",
    "            #confidence_df[filename] = confidence_list\n",
    "            print(row_final)\n",
    "\n",
    "    # Save the DataFrames to Excel files\n",
    "    #text_df.to_excel(output_text_excel_path, index=False)\n",
    "    #confidence_df.to_excel(output_confidence_excel_path, index=False)\n",
    "\n",
    "    print(f\"Text results saved to {output_text_excel_path}\")\n",
    "    print(f\"Confidence results saved to {output_confidence_excel_path}\")\n",
    "    return\n",
    "\n",
    "def check_append_content(content: list, check: str, output: list, check2: str = None):\n",
    "    \"\"\"\n",
    "    Check if key words are in the OCR content, store it to output\n",
    "    \n",
    "    Intput:\n",
    "        content (list): the OCR output to be checked\n",
    "        check (str): the key word\n",
    "        output (list): final results\n",
    "    \"\"\"\n",
    "    if check in content:\n",
    "        return output.append(content)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./jpg/page_1.jpg\n",
      "Paragraph confidence: 0.3065045475959778\n",
      "Paragraph confidence: 0.39925214648246765\n",
      "Paragraph confidence: 0.7906478047370911\n",
      "Paragraph confidence: 0.9778670072555542\n",
      "Paragraph confidence: 0.990152895450592\n",
      "Paragraph confidence: 0.9369380474090576\n",
      "Paragraph confidence: 0.9886298775672913\n",
      "Paragraph confidence: 0.9803629517555237\n",
      "Paragraph confidence: 0.6652325391769409\n",
      "Paragraph confidence: 0.970495879650116\n",
      "Paragraph confidence: 0.9884873032569885\n",
      "Paragraph confidence: 0.9723023772239685\n",
      "Paragraph confidence: 0.9610694050788879\n",
      "Paragraph confidence: 0.779672384262085\n",
      "Paragraph confidence: 0.9762927293777466\n",
      "Paragraph confidence: 0.9602194428443909\n",
      "Paragraph confidence: 0.9465628862380981\n",
      "Paragraph confidence: 0.9916848540306091\n",
      "Paragraph confidence: 0.9738894104957581\n",
      "所属国際沿岸海洋研究センター名技術専門職員\n",
      "Paragraph confidence: 0.9892253875732422\n",
      "Paragraph confidence: 0.9857959747314453\n",
      "Paragraph confidence: 0.9902837872505188\n",
      "Paragraph confidence: 0.9535636901855469\n",
      "Paragraph confidence: 0.7619466185569763\n",
      "Paragraph confidence: 0.9788004159927368\n",
      "Paragraph confidence: 0.9832701086997986\n",
      "Paragraph confidence: 0.9847502708435059\n",
      "Paragraph confidence: 0.9446191191673279\n",
      "Paragraph confidence: 0.639995813369751\n",
      "Paragraph confidence: 0.9877959489822388\n",
      "Paragraph confidence: 0.39617443084716797\n",
      "Paragraph confidence: 0.9790289402008057\n",
      "Paragraph confidence: 0.9513288140296936\n",
      "['舟艇の名称グランメーユ', '平成31年4月24日15時00分乗船者氏名平野、鈴木', '所属国際沿岸海洋研究センター名技術専門職員', '平成31年4月24日15時00分', '平成年月日']\n",
      "Processing image: ./jpg/page_2.jpg\n",
      "Paragraph confidence: 0.4619053900241852\n",
      "Paragraph confidence: 0.4229847490787506\n",
      "Paragraph confidence: 0.9489170908927917\n",
      "Paragraph confidence: 0.9838473796844482\n",
      "Paragraph confidence: 0.9823175072669983\n",
      "Paragraph confidence: 0.3375551998615265\n",
      "Paragraph confidence: 0.9398241639137268\n",
      "Paragraph confidence: 0.9258203506469727\n",
      "Paragraph confidence: 0.9815310835838318\n",
      "Paragraph confidence: 0.9829185605049133\n",
      "Paragraph confidence: 0.902491569519043\n",
      "Paragraph confidence: 0.9886147379875183\n",
      "Paragraph confidence: 0.9889814853668213\n",
      "Paragraph confidence: 0.9765862226486206\n",
      "Paragraph confidence: 0.9583536386489868\n",
      "Paragraph confidence: 0.9673389792442322\n",
      "Paragraph confidence: 0.8791937828063965\n",
      "Paragraph confidence: 0.9692897796630859\n",
      "Paragraph confidence: 0.5404173731803894\n",
      "Paragraph confidence: 0.8344108462333679\n",
      "Paragraph confidence: 0.18567439913749695\n",
      "Paragraph confidence: 0.9793711304664612\n",
      "Paragraph confidence: 0.9229732751846313\n",
      "所属国際沿岸海洋研究也沒一\n",
      "Paragraph confidence: 0.9666274189949036\n",
      "Paragraph confidence: 0.90050208568573\n",
      "Paragraph confidence: 0.9071658253669739\n",
      "Paragraph confidence: 0.6154636144638062\n",
      "Paragraph confidence: 0.9777770638465881\n",
      "Paragraph confidence: 0.9675142168998718\n",
      "Paragraph confidence: 0.7299026250839233\n",
      "Paragraph confidence: 0.8007295727729797\n",
      "Paragraph confidence: 0.9839190244674683\n",
      "Paragraph confidence: 0.9216493964195251\n",
      "Paragraph confidence: 0.8554529547691345\n",
      "Paragraph confidence: 0.970072865486145\n",
      "Paragraph confidence: 0.9786970615386963\n",
      "Paragraph confidence: 0.6857504844665527\n",
      "Paragraph confidence: 0.7627744674682617\n",
      "Paragraph confidence: 0.8411235809326172\n",
      "['グランメーユ', '平成31年4月24日7時30分', '平成31年4月24日', '所属国際沿岸海洋研究也沒一', '平成31年4月24日']\n",
      "Processing image: ./jpg/page_3.jpg\n",
      "Paragraph confidence: 0.6659743189811707\n",
      "Paragraph confidence: 0.737830638885498\n",
      "Paragraph confidence: 0.8559250831604004\n",
      "Paragraph confidence: 0.9904239773750305\n",
      "Paragraph confidence: 0.9898954629898071\n",
      "Paragraph confidence: 0.9745952486991882\n",
      "Paragraph confidence: 0.9555267095565796\n",
      "Paragraph confidence: 0.9162930250167847\n",
      "Paragraph confidence: 0.9843169450759888\n",
      "Paragraph confidence: 0.9855964183807373\n",
      "Paragraph confidence: 0.9866975545883179\n",
      "Paragraph confidence: 0.32856202125549316\n",
      "Paragraph confidence: 0.7851887345314026\n",
      "Paragraph confidence: 0.9878641366958618\n",
      "Paragraph confidence: 0.9794332385063171\n",
      "Paragraph confidence: 0.5767300128936768\n",
      "Paragraph confidence: 0.9734390377998352\n",
      "Paragraph confidence: 0.9274954795837402\n",
      "Paragraph confidence: 0.878431499004364\n",
      "Paragraph confidence: 0.8802352547645569\n",
      "Paragraph confidence: 0.17197760939598083\n",
      "Paragraph confidence: 0.9222158789634705\n",
      "Paragraph confidence: 0.7562991976737976\n",
      "Paragraph confidence: 0.5452852249145508\n",
      "Paragraph confidence: 0.8121790885925293\n",
      "Paragraph confidence: 0.9814921617507935\n",
      "Paragraph confidence: 0.8890261054039001\n",
      "Paragraph confidence: 0.9712873101234436\n",
      "Paragraph confidence: 0.966282308101654\n",
      "Paragraph confidence: 0.9498776793479919\n",
      "Paragraph confidence: 0.7484115362167358\n",
      "Paragraph confidence: 0.44961997866630554\n",
      "['本件了承しました。平成3年4月24日', '平成31年4月23日8時30分~9時30分', '運航日時平成3/年4月23日8時30分~9時30分']\n",
      "Processing image: ./jpg/page_4.jpg\n",
      "Paragraph confidence: 0.20033003389835358\n",
      "Paragraph confidence: 0.18180397152900696\n",
      "Paragraph confidence: 0.907647430896759\n",
      "Paragraph confidence: 0.9832955002784729\n",
      "Paragraph confidence: 0.9739030599594116\n",
      "Paragraph confidence: 0.9244304895401001\n",
      "Paragraph confidence: 0.3843003213405609\n",
      "Paragraph confidence: 0.9690544009208679\n",
      "Paragraph confidence: 0.9877292513847351\n",
      "Paragraph confidence: 0.9278476238250732\n",
      "Paragraph confidence: 0.7708079814910889\n",
      "Paragraph confidence: 0.9824735522270203\n",
      "Paragraph confidence: 0.9910945296287537\n",
      "Paragraph confidence: 0.9784822463989258\n",
      "Paragraph confidence: 0.9804419875144958\n",
      "Paragraph confidence: 0.9661154747009277\n",
      "Paragraph confidence: 0.6621652841567993\n",
      "Paragraph confidence: 0.9298428893089294\n",
      "Paragraph confidence: 0.5921687483787537\n",
      "Paragraph confidence: 0.6137327551841736\n",
      "Paragraph confidence: 0.3558245301246643\n",
      "Paragraph confidence: 0.9755149483680725\n",
      "Paragraph confidence: 0.2044612318277359\n",
      "Paragraph confidence: 0.908987283706665\n",
      "Paragraph confidence: 0.6896892189979553\n",
      "Paragraph confidence: 0.7473047375679016\n",
      "Paragraph confidence: 0.9727494716644287\n",
      "Paragraph confidence: 0.7372205257415771\n",
      "Paragraph confidence: 0.9896627068519592\n",
      "Paragraph confidence: 0.9792531728744507\n",
      "Paragraph confidence: 0.9799357652664185\n",
      "Paragraph confidence: 0.9611035585403442\n",
      "Paragraph confidence: 0.9802793264389038\n",
      "Paragraph confidence: 0.9826906323432922\n",
      "Paragraph confidence: 0.6350659132003784\n",
      "Paragraph confidence: 0.7290496230125427\n",
      "Paragraph confidence: 0.8581597805023193\n",
      "Paragraph confidence: 0.7348275780677795\n",
      "Paragraph confidence: 0.4389698803424835\n",
      "['平成3', '平成31年4月24日', '平成年', '平成31年4月24日9時00分~10時30分']\n",
      "Processing image: ./jpg/page_5.jpg\n",
      "Paragraph confidence: 0.4231519401073456\n",
      "Paragraph confidence: 0.3507494032382965\n",
      "Paragraph confidence: 0.8221821784973145\n",
      "Paragraph confidence: 0.9178012609481812\n",
      "Paragraph confidence: 0.9810029864311218\n",
      "Paragraph confidence: 0.9806610941886902\n",
      "Paragraph confidence: 0.9876378774642944\n",
      "Paragraph confidence: 0.9886022806167603\n",
      "Paragraph confidence: 0.8313573002815247\n",
      "Paragraph confidence: 0.8640241622924805\n",
      "Paragraph confidence: 0.9785189032554626\n",
      "Paragraph confidence: 0.936311662197113\n",
      "Paragraph confidence: 0.9806192517280579\n",
      "Paragraph confidence: 0.88933265209198\n",
      "Paragraph confidence: 0.9888530969619751\n",
      "Paragraph confidence: 0.9785510301589966\n",
      "Paragraph confidence: 0.5145871639251709\n",
      "Paragraph confidence: 0.9906814694404602\n",
      "Paragraph confidence: 0.8938472270965576\n",
      "Paragraph confidence: 0.975087583065033\n",
      "Paragraph confidence: 0.953717052936554\n",
      "Paragraph confidence: 0.7913064360618591\n",
      "Paragraph confidence: 0.7391402721405029\n",
      "Paragraph confidence: 0.9807207584381104\n",
      "Paragraph confidence: 0.9598098993301392\n",
      "Paragraph confidence: 0.8553826808929443\n",
      "Paragraph confidence: 0.9730516672134399\n",
      "Paragraph confidence: 0.4726637005805969\n",
      "Paragraph confidence: 0.8676793575286865\n",
      "Paragraph confidence: 0.14633934199810028\n",
      "Paragraph confidence: 0.6410271525382996\n",
      "Paragraph confidence: 0.5408194065093994\n",
      "Paragraph confidence: 0.6472313404083252\n",
      "Paragraph confidence: 0.5984183549880981\n",
      "Paragraph confidence: 0.5817111730575562\n",
      "['平成年月日', '平成3/年4月22日7時30分~/0時30分', '平成31年4月22日9時30分~10時30分']\n",
      "Text results saved to ./\n",
      "Confidence results saved to ./\n"
     ]
    }
   ],
   "source": [
    "process_images_in_directory(directory_path=jpg_path, output_text_excel_path=\"./\", output_confidence_excel_path=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
