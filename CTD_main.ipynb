{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "TODO\n",
    "- Note that: all old CTD filenames are same pattern, as well as new -> total 2 patterns\n",
    "- Three sections:\n",
    "    1) compile RINNKO CTD data (done,2023/10/30)\n",
    "    2) compile 震災後 compactCTD data (done,2023/11/26)\n",
    "    3) compile 被災したPCより吸い出せたもの compactCTD data (ing,2024/02/08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: define class and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub 0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub 1: define class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# A class to store and parse filename:        #\n",
    "#    - input:                                 #\n",
    "#       fn: filename                          #\n",
    "#       pattern: filename pattern to match    #\n",
    "#    - output:                                #\n",
    "#       several methods to call               #\n",
    "###############################################\n",
    "\n",
    "class filenameClass:\n",
    "    def __init__(self, fn, pattern=None):\n",
    "        self.fn = fn\n",
    "        # TODO change pattern for different CTD folders: make it a variable\n",
    "        self.pattern = pattern\n",
    "        return\n",
    "\n",
    "    def fn_parser(self):\n",
    "        # define regex for CTD RINKO data: date, time, sondeName, sondeNumber, dummy, fieltype\n",
    "        # match filename and pattern\n",
    "        def checkAndAssignDate(match):\n",
    "            if 'date' in match.groupdict():\n",
    "                self.date_org = match.group('date')\n",
    "                self.yyyy, self.mm, self.dd = self.date_org[0:4],self.date_org[4:6],self.date_org[6:]\n",
    "                # save another date format\n",
    "                self.date = f\"{self.yyyy}-{self.mm}-{self.dd}\"\n",
    "                return\n",
    "            else:\n",
    "                self.date_org = None\n",
    "                self.yyyy, self.mm, self.dd = None, None, None\n",
    "                # save another date format\n",
    "                self.date = None\n",
    "                return \n",
    "        def checkAndAssignTime(match):\n",
    "            if 'time' in match.groupdict():\n",
    "                self.time_org = match.group('time')\n",
    "                # save another time format\n",
    "                self.hh, self.min = self.time_org[0:2], self.time_org[2:]\n",
    "                return\n",
    "            else:\n",
    "                self.time_org = None\n",
    "                self.hh, self.min = None, None\n",
    "                return\n",
    "        \n",
    "        def checkAndAssignDummy(match):\n",
    "            if 'dummy' in match.groupdict():\n",
    "                self.dummy = match.group('dummy')\n",
    "                self.ss = self.dummy[-2:]\n",
    "                self.time = f\"{self.hh}:{self.min}:{self.ss}\"\n",
    "                return\n",
    "            else:\n",
    "                self.dummy = None\n",
    "                self.ss = None\n",
    "                self.time = None\n",
    "                return \n",
    "        \n",
    "        def checkAndAssignSondeName(match):\n",
    "            if 'sonde_name' in match.groupdict():\n",
    "                self.sonde_name = match.group('sonde_name')\n",
    "                return\n",
    "            else:\n",
    "                self.sonde_name = None\n",
    "                return \n",
    "            \n",
    "        def checkAndAssignSondeNumber(match):\n",
    "            if 'sonde_number' in match.groupdict():\n",
    "                self.sonde_number = match.group('sonde_number')\n",
    "                return\n",
    "            else:\n",
    "                self.sonde_number = None\n",
    "                return \n",
    "            \n",
    "        def checkAndAssignFiletype(match):\n",
    "            if 'filetype' in match.groupdict():\n",
    "                self.file_type = match.group('filetype')\n",
    "                return\n",
    "            else:\n",
    "                self.file_type = None\n",
    "                return \n",
    "        \n",
    "        def checkAndAssignSno(match):\n",
    "            if 'sno' in match.groupdict():\n",
    "                self.sno = match.group('sno')\n",
    "                # TCDKU is sonde name for compactCTD data\n",
    "                if self.sno == '103':\n",
    "                    self.sonde_name = 'TCDKU'\n",
    "                # also, if sno, hh mm ss is in time_org\n",
    "                self.hh,self.min,self.ss = self.time_org[:2],self.time_org[2:4],self.time_org[4:]\n",
    "                self.time = f\"{self.hh}:{self.min}:{self.ss}\"\n",
    "                return\n",
    "            else:\n",
    "                self.sno = None\n",
    "                return \n",
    "        \n",
    "        def checkAndAssignBklno(match):\n",
    "            if 'blkno' in match.groupdict():\n",
    "                self.blkno = match.group('blkno')\n",
    "                return\n",
    "            else:\n",
    "                self.blkno = None\n",
    "                return \n",
    "        \n",
    "        # main dish\n",
    "        match = re.match(self.pattern, self.fn)\n",
    "        if match:\n",
    "            # check and assign self values in match\n",
    "            checkAndAssignDate(match)\n",
    "            checkAndAssignTime(match)\n",
    "            checkAndAssignDummy(match)\n",
    "            checkAndAssignSondeName(match)\n",
    "            checkAndAssignSondeNumber(match)\n",
    "            checkAndAssignFiletype(match)\n",
    "            # for old CTD: sno==serial number, blkno==block number, assign time in Sno\n",
    "            checkAndAssignSno(match)\n",
    "            checkAndAssignBklno(match)\n",
    "        else:\n",
    "            raise f\"Filename {self.fn} does not match the pattern!!\"\n",
    "\n",
    "    def listUpAttr(self, form=\"1\"):\n",
    "        # form \"1\" is numberic date time, \"2\" is usual date format\n",
    "        if (self.file_type[-1:] == 'w' or self.file_type[-1:] == 'W'):\n",
    "            # if file type is raw\n",
    "            if self.sno is None and self.blkno is None:\n",
    "                # if no sno record\n",
    "                self.list = np.array([self.sonde_name, self.sonde_number, self.date_org if form==\"1\" else self.date,\n",
    "                                      self.time, 1,\n",
    "                                      None,  None, None])\n",
    "            else:\n",
    "                # else, add block number to record: sonde number == sno i guess?\n",
    "                self.list = np.array([self.sonde_name, self.sno, self.blkno, self.date_org if form==\"1\" else self.date,\n",
    "                                      self.time, 1,\n",
    "                                      None,  None, None])\n",
    "        elif (self.file_type[-1:] == 'v'or self.file_type[-1:] == 'V'):\n",
    "            # if file type is csv\n",
    "            if self.sno is None and self.blkno is None:\n",
    "                self.list = np.array([self.sonde_name, self.sonde_number, self.date_org if form==\"1\" else self.date,\n",
    "                                      self.time, None,\n",
    "                                      1, None, None])\n",
    "            else:\n",
    "                # else, add block number to record: sonde number == sno i guess?\n",
    "                self.list = np.array([self.sonde_name, self.sno, self.blkno, self.date_org if form==\"1\" else self.date,\n",
    "                                      self.time, None,\n",
    "                                      1,  None, None])\n",
    "        else:\n",
    "            print(f\"File type: {self.file_type}\")\n",
    "            raise \"File type does not match 'raw' or 'csv'!!\"\n",
    "        return self.list\n",
    "\n",
    "    def getDate(self):\n",
    "        return self.date_org, \"or\", self.date\n",
    "\n",
    "    def getTime(self):\n",
    "        return self.time_org, \"or\", self.time\n",
    "\n",
    "    def getSondeName(self):\n",
    "        return self.sonde_name\n",
    "\n",
    "    def getSondeNumber(self):\n",
    "        return self.sonde_number\n",
    "\n",
    "    def getFileType(self):\n",
    "        return self.file_type\n",
    "    \n",
    "    def getSno(self):\n",
    "        return self.sno\n",
    "    \n",
    "    def getBlkno(self):\n",
    "        return self.blkno\n",
    "    \n",
    "    def printPattern(self):\n",
    "        print(f\"Input pattern: {self.pattern}\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub 2: define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define functions: list-out filenames, print all attributes\n",
    "def listOut_fn(path):\n",
    "    # use os to retrieve list of files, and get individual elements\n",
    "    all_files = os.listdir(path)\n",
    "    # list all files except folder\n",
    "    all_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    return all_files\n",
    "\n",
    "def printAttr(file):\n",
    "    print(\"Date:\", file.getDate())\n",
    "    print(\"Time:\", file.getTime())\n",
    "    print(\"Sonde Name:\", file.getSondeName())\n",
    "    print(\"Serial number:\", file.getSno())\n",
    "    print(\"Sonde ID:\", file.getSondeNumber())\n",
    "    print(\"Block number:\", file.getBlkno())\n",
    "    print(\"Filetype:\", file.getFileType())\n",
    "    return\n",
    "\n",
    "def readFilename(fn, date_form=\"1\", pattern=None):\n",
    "    # handle file name and parse it\n",
    "    fileClass = filenameClass(fn=fn, pattern=pattern)\n",
    "    fileClass.fn_parser()\n",
    "    list = fileClass.listUpAttr(form=date_form)\n",
    "    return fileClass,list\n",
    "\n",
    "def loopAndStack(fn_list,pattern,date_form=\"1\"):\n",
    "    # loop over all fns and stack it into one numpy array\n",
    "    fn0 = fn_list[0]\n",
    "    file, list_all = readFilename(fn=fn0, date_form=date_form,pattern=pattern)\n",
    "    for fn in fn_list[1:]:\n",
    "        file, list = readFilename(fn=fn, date_form=date_form,pattern=pattern)\n",
    "        # vertically stack all\n",
    "        list_all = np.vstack((list_all, list))\n",
    "    return list_all\n",
    "\n",
    "def mergeStackedList(list_all, col_names, groupby):\n",
    "    # merge the array to check if it has csv and raw\n",
    "    df = pd.DataFrame(list_all,columns=col_names)\n",
    "    # if sondeName, SondeNumber, startDate, startTime are same, sum up 'raw' & 'csv' columns\n",
    "    merged_df = df.groupby(groupby).agg(np.sum)\n",
    "    return merged_df\n",
    "\n",
    "def findIncompleteData(results):\n",
    "    mask = results_df[(results_df['raw']==0) | (results_df['csv']==0)]\n",
    "    if len(mask):\n",
    "        print(mask)\n",
    "        print(f\"Length of incomplete data: {len(mask)}\")\n",
    "        return mask\n",
    "    else:\n",
    "        print(\"Results have equal raw and csv.\")\n",
    "        return \n",
    "\n",
    "def checkFileLength(len_fn_raw,len_dummy,len_results,len_single):\n",
    "    len_both = len_results-len_single # files that have both csv and raw\n",
    "    total = len_dummy + (len_both)*2 + len_single\n",
    "    # if len(filename list) == dummy + len(double)*2 + single\n",
    "    if total == len_fn_raw:\n",
    "        print(f\"Length matches.\")\n",
    "        print(f\"Fn raw: {len_fn_raw}\")\n",
    "        print(f\"Total: {total}\")\n",
    "        print(f\"Dummy: {len_dummy}\")\n",
    "        print(f\"Files [csv && raw]: {len_both}\")\n",
    "        print(f\"Files [csv // raw]: {len_single}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Length does not match!!\")\n",
    "        print(f\"Fn raw: {len_fn_raw}\")\n",
    "        print(f\"Total: {total}\")\n",
    "        print(f\"Dummy: {len_dummy}\")\n",
    "        print(f\"Files [csv && raw]: {len_both}\")\n",
    "        print(f\"Files [csv // raw]: {len_single}\")\n",
    "        return False\n",
    "    \n",
    "def countAndRemove99999(fn_list):\n",
    "    dummy_fn = [item for item in fn_list if item[-9:-4]=='99999']\n",
    "    count = len(dummy_fn)\n",
    "    print(f\"Dummy files: {dummy_fn}\")\n",
    "    print(f\"Length of dummy file: {count}\")\n",
    "    output = [item for item in fn_list if item not in dummy_fn]\n",
    "    return dummy_fn, count, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub 3: Configurate constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Configure regex patterns below #################\n",
    "pattern_RINNKO = r'^(?P<date>\\d{8})(?P<time>\\d{4})_(?P<sonde_name>[A-Z\\d-]+)_(?P<sonde_number>\\d{4})_(?P<dummy>\\d{6})\\.(?P<filetype>[a-zA-Z]+)$'\n",
    "pattern_afterEQ = r'^(?P<date>\\d{8})_(?P<time>\\d{6})_SNo_(?P<sno>\\d{3})_BlkNo_(?P<blkno>\\d{4})\\.(?P<filetype>[a-zA-Z]+)$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: compile RINNKO CTD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############## Configure data path of data below #################\n",
    "dt_path = \"../data/RINKO_Data/\"\n",
    "# config year below: single year or \"all\"\n",
    "#year = '2014'\n",
    "year = \"all\"\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw list: 5217\n",
      "Dummy files: []\n",
      "Length of dummy file: 0\n",
      "Length of new list:  5217\n"
     ]
    }
   ],
   "source": [
    "# Read and store all filenames\n",
    "RINKO_fn = listOut_fn(dt_path)\n",
    "print(f\"Length of raw list: {len(RINKO_fn)}\")\n",
    "if year != \"all\":\n",
    "    filename_list = [fn for fn in RINKO_fn if fn[0:4]==year]\n",
    "else:\n",
    "    filename_list = [fn for fn in RINKO_fn if fn[0]!=\"$\"]\n",
    "    pass\n",
    "# check fns && remove dummy files (e.g., 99999 at last 5 digits)\n",
    "dummy_fn, dummy_count, filename_list = countAndRemove99999(fn_list=filename_list)\n",
    "print('Length of new list: ', len(filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking a sample case to test the code:\n",
      "Input pattern: ^(?P<date>\\d{8})(?P<time>\\d{4})_(?P<sonde_name>[A-Z\\d-]+)_(?P<sonde_number>\\d{4})_(?P<dummy>\\d{6})\\.(?P<filetype>[a-zA-Z]+)$\n",
      "Date: ('20140303', 'or', '2014-03-03')\n",
      "Time: ('1502', 'or', '15:02:05')\n",
      "Sonde Name: ASTD102-ALC-R02\n",
      "Serial number: None\n",
      "Sonde ID: 0254\n",
      "Block number: None\n",
      "Filetype: raw\n",
      "The whole list is like:  ['ASTD102-ALC-R02' '0254' '2014-03-03' '15:02:05' 1 None None None]\n",
      "Some elements to check:  ['0254' '2014-03-03' '15:02:05']\n"
     ]
    }
   ],
   "source": [
    "##############testing pattern: uncomment below ##################\n",
    "#filename = \"201403170853_ASTD102-ALC-R02_0254_085318.csv\"\n",
    "#filename = \"201403250855_ASTD102-ALC-R02_0254_085522.csv\"\n",
    "#filename = RINKO_fn[99]\n",
    "# TODO: '$' added to datetime, for some cases\n",
    "#########################################\n",
    "print(\"Checking a sample case to test the code:\")\n",
    "file, list = readFilename(fn=filename_list[1], date_form=\"2\",pattern=pattern_RINNKO)\n",
    "file.printPattern()\n",
    "# Check\n",
    "printAttr(file)\n",
    "print(\"The whole list is like: \", list)\n",
    "print(\"Some elements to check: \",list[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ASTD102-ALC-R02' '0254' '2014-03-03' ... 1 None None]\n",
      " ['ASTD102-ALC-R02' '0254' '2014-03-03' ... None None None]\n",
      " ['ASTD102-ALC-R02' '0254' '2014-03-17' ... 1 None None]\n",
      " ...\n",
      " ['ASTD102-ALC-R02' '0611' '2023-08-23' ... None None None]\n",
      " ['ASTD102-ALC-R02' '0611' '2023-08-24' ... 1 None None]\n",
      " ['ASTD102-ALC-R02' '0611' '2023-08-24' ... None None None]]\n"
     ]
    }
   ],
   "source": [
    "# Loop and stack all parsed file names\n",
    "results = loopAndStack(fn_list=filename_list, date_form=\"2\",pattern=pattern_RINNKO)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that the DF below is sorted by SondeNumber!\n",
      "                                                  raw  csv Latitude Longitude\n",
      "SondeName       SondeNumber StartDate  StartTime                             \n",
      "ASTD102-ALC-R02 0143        2016-03-30 09:28:09     1    1  Unknown   Unknown\n",
      "                                       09:31:12     1    1  Unknown   Unknown\n",
      "                                       09:36:36     1    1  Unknown   Unknown\n",
      "                            2016-06-21 08:47:12     1    1  Unknown   Unknown\n",
      "                            2016-11-21 09:00:52     1    1  Unknown   Unknown\n",
      "...                                               ...  ...      ...       ...\n",
      "                0611        2023-08-23 08:03:25     1    1  Unknown   Unknown\n",
      "                                       08:34:39     1    1  Unknown   Unknown\n",
      "                                       08:44:54     1    1  Unknown   Unknown\n",
      "                                       08:56:21     1    1  Unknown   Unknown\n",
      "                            2023-08-24 07:52:48     1    1  Unknown   Unknown\n",
      "\n",
      "[2609 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge stacked list and change to pd.DataFrame\n",
    "print(\"Note that the DF below is sorted by SondeNumber!\")\n",
    "results_df = mergeStackedList(results,col_names=['SondeName','SondeNumber','StartDate','StartTime','raw','csv','Latitude','Longitude'],\n",
    "                             groupby=['SondeName','SondeNumber','StartDate','StartTime'])\n",
    "# Lat lon are unknown\n",
    "results_df.Latitude = 'Unknown'\n",
    "results_df.Longitude = 'Unknown'\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of files:  5217\n",
      "Length of DF:  2609\n",
      "                                                  raw  csv Latitude Longitude\n",
      "SondeName       SondeNumber StartDate  StartTime                             \n",
      "ASTD102-ALC-R02 0254        2018-07-19 09:45:19     1    0  Unknown   Unknown\n",
      "Length of incomplete data: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Numer of files: \", len(filename_list))\n",
    "print(\"Length of DF: \", results_df.shape[0])\n",
    "# check if some rows has no raw or csv file, if yes, print it out.\n",
    "incomplete_data = findIncompleteData(results=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length matches.\n",
      "Fn raw: 5217\n",
      "Total: 5217\n",
      "Dummy: 0\n",
      "Files [csv && raw]: 2608\n",
      "Files [csv // raw]: 1\n"
     ]
    }
   ],
   "source": [
    "# check lengths\n",
    "checking = checkFileLength(len_fn_raw=len(RINKO_fn),len_dummy=dummy_count,len_results=len(results_df),len_single=len(incomplete_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved, at ./output/\n"
     ]
    }
   ],
   "source": [
    "# save df to csv\n",
    "if checking:\n",
    "    save_path = \"./output/\"\n",
    "    results_df.to_csv(f'{save_path}CTD_RINNKO_{year}.csv')\n",
    "    print(f\"Saved, at {save_path}\")\n",
    "else:\n",
    "    print(\"No save -> length did not match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: compile 震災後 compactCTD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra: an extra function to count and remove dummy CTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Configure data path of data below #################\n",
    "dt_path = \"../data/CompactCTD Data（震災後）/\"\n",
    "# config year below: single year or \"all\"\n",
    "#year = '2014'\n",
    "year = \"all\"\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy files: ['20200124_144542_SNo_99999_BlkNo_99999.Csv', '20200124_144542_SNo_99999_BlkNo_99999.RAW', '20200228_104715_SNo_99999_BlkNo_99999.Csv', '20200228_104715_SNo_99999_BlkNo_99999.RAW', '20200309_132906_SNo_99999_BlkNo_99999.Csv', '20200309_132906_SNo_99999_BlkNo_99999.RAW', '20200309_133221_SNo_99999_BlkNo_99999.Csv', '20200309_133221_SNo_99999_BlkNo_99999.RAW', '20200309_133603_SNo_99999_BlkNo_99999.Csv', '20200309_133603_SNo_99999_BlkNo_99999.RAW', '20200309_133819_SNo_99999_BlkNo_99999.Csv', '20200309_133819_SNo_99999_BlkNo_99999.RAW', '20200312_111954_SNo_99999_BlkNo_99999.Csv', '20200312_111954_SNo_99999_BlkNo_99999.RAW', '20200312_112351_SNo_99999_BlkNo_99999.Csv', '20200312_112351_SNo_99999_BlkNo_99999.RAW', '20200312_114450_SNo_99999_BlkNo_99999.Csv', '20200312_114450_SNo_99999_BlkNo_99999.RAW']\n",
      "Length of dummy file: 18\n",
      "Length of new list:  1661\n"
     ]
    }
   ],
   "source": [
    "# Read and store all filenames\n",
    "afterEQ_fn = listOut_fn(dt_path)\n",
    "if year != \"all\":\n",
    "    filename_list = [fn for fn in afterEQ_fn if fn[0:4]==year]\n",
    "else:\n",
    "    filename_list = [fn for fn in afterEQ_fn if fn[0]!=\"$\"]\n",
    "# check fns && remove dummy files (e.g., 99999 at last 5 digits)\n",
    "dummy_fn, dummy_count, filename_list = countAndRemove99999(fn_list=filename_list)\n",
    "print('Length of new list: ', len(filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking a sample case to test the code:\n",
      "Input pattern: ^(?P<date>\\d{8})_(?P<time>\\d{6})_SNo_(?P<sno>\\d{3})_BlkNo_(?P<blkno>\\d{4})\\.(?P<filetype>[a-zA-Z]+)$\n",
      "Date: ('20120306', 'or', '2012-03-06')\n",
      "Time: ('083509', 'or', '08:35:09')\n",
      "Sonde Name: TCDKU\n",
      "Serial number: 103\n",
      "Sonde ID: None\n",
      "Block number: 0002\n",
      "Filetype: Csv\n",
      "The whole list is like:  ['TCDKU' '103' '0002' '2012-03-06' '08:35:09' None 1 None None]\n",
      "Some elements to check:  ['103' '0002' '2012-03-06']\n"
     ]
    }
   ],
   "source": [
    "# testing one single case\n",
    "print(\"Checking a sample case to test the code:\")\n",
    "file, list = readFilename(fn=filename_list[1], date_form=\"2\",pattern=pattern_afterEQ)\n",
    "file.printPattern()\n",
    "# Check\n",
    "printAttr(file)\n",
    "print(\"The whole list is like: \", list)\n",
    "print(\"Some elements to check: \",list[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TCDKU' '103' '0001' ... 1 None None]\n",
      " ['TCDKU' '103' '0002' ... 1 None None]\n",
      " ['TCDKU' '103' '0003' ... 1 None None]\n",
      " ...\n",
      " ['TCDKU' '103' '0145' ... None None None]\n",
      " ['TCDKU' '103' '0146' ... 1 None None]\n",
      " ['TCDKU' '103' '0146' ... None None None]]\n"
     ]
    }
   ],
   "source": [
    "# Loop and stack all parsed file names\n",
    "results = loopAndStack(fn_list=filename_list, date_form=\"2\",pattern=pattern_afterEQ)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that the DF below is sorted by SondeNumber!\n",
      "                                                                     raw  csv  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime             \n",
      "TCDKU     103               0001               2012-03-05 11:54:37     0    1   \n",
      "                                               2013-12-02 10:05:04     1    1   \n",
      "                                               2013-12-06 11:08:02     1    1   \n",
      "                                               2013-12-13 13:27:48     1    1   \n",
      "                                               2014-01-06 11:29:00     1    1   \n",
      "...                                                                  ...  ...   \n",
      "                            0248               2020-03-11 13:54:06     1    1   \n",
      "                            0249               2020-03-11 13:54:43     1    1   \n",
      "                            0250               2020-03-11 13:56:32     1    1   \n",
      "                            0251               2020-03-11 13:57:19     1    1   \n",
      "                            0252               2020-03-11 13:58:02     1    1   \n",
      "\n",
      "                                                                    Latitude  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2012-03-05 11:54:37   Unknown   \n",
      "                                               2013-12-02 10:05:04   Unknown   \n",
      "                                               2013-12-06 11:08:02   Unknown   \n",
      "                                               2013-12-13 13:27:48   Unknown   \n",
      "                                               2014-01-06 11:29:00   Unknown   \n",
      "...                                                                      ...   \n",
      "                            0248               2020-03-11 13:54:06   Unknown   \n",
      "                            0249               2020-03-11 13:54:43   Unknown   \n",
      "                            0250               2020-03-11 13:56:32   Unknown   \n",
      "                            0251               2020-03-11 13:57:19   Unknown   \n",
      "                            0252               2020-03-11 13:58:02   Unknown   \n",
      "\n",
      "                                                                    Longitude  \n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2012-03-05 11:54:37    Unknown  \n",
      "                                               2013-12-02 10:05:04    Unknown  \n",
      "                                               2013-12-06 11:08:02    Unknown  \n",
      "                                               2013-12-13 13:27:48    Unknown  \n",
      "                                               2014-01-06 11:29:00    Unknown  \n",
      "...                                                                       ...  \n",
      "                            0248               2020-03-11 13:54:06    Unknown  \n",
      "                            0249               2020-03-11 13:54:43    Unknown  \n",
      "                            0250               2020-03-11 13:56:32    Unknown  \n",
      "                            0251               2020-03-11 13:57:19    Unknown  \n",
      "                            0252               2020-03-11 13:58:02    Unknown  \n",
      "\n",
      "[840 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge stacked list and change to pd.DataFrame\n",
    "print(\"Note that the DF below is sorted by SondeNumber!\")\n",
    "results_df = mergeStackedList(results,col_names=['SondeName','SerialNumber(Sno)','BlockNumber(Blkno)','StartDate','StartTime','raw','csv','Latitude','Longitude'],\n",
    "                             groupby=['SondeName','SerialNumber(Sno)','BlockNumber(Blkno)','StartDate','StartTime'])\n",
    "\n",
    "# Lat lon are unknown\n",
    "results_df.Latitude = 'Unknown'\n",
    "results_df.Longitude = 'Unknown'\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of files:  1661\n",
      "Length of DF:  840\n",
      "                                                                     raw  csv  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime             \n",
      "TCDKU     103               0001               2012-03-05 11:54:37     0    1   \n",
      "                            0002               2012-03-06 08:35:09     0    1   \n",
      "                            0003               2012-03-08 09:03:01     0    1   \n",
      "                            0004               2012-03-09 11:42:31     0    1   \n",
      "                            0005               2012-03-12 10:34:24     0    1   \n",
      "                            0006               2012-03-13 08:45:29     0    1   \n",
      "                            0007               2012-03-14 08:45:26     0    1   \n",
      "                            0008               2012-03-16 08:56:43     0    1   \n",
      "                            0009               2012-03-21 08:17:42     0    1   \n",
      "                            0023               2012-03-22 10:34:40     0    1   \n",
      "                            0024               2012-03-22 11:13:34     0    1   \n",
      "                            0025               2012-03-22 11:16:26     0    1   \n",
      "                            0026               2012-03-22 11:23:39     0    1   \n",
      "                            0027               2012-03-22 11:27:07     0    1   \n",
      "                            0028               2012-03-22 11:29:07     0    1   \n",
      "                            0029               2012-03-22 12:00:12     0    1   \n",
      "                            0030               2012-03-22 12:02:57     0    1   \n",
      "                            0031               2012-03-22 12:17:44     0    1   \n",
      "                            0244               2020-03-11 13:50:24     1    0   \n",
      "\n",
      "                                                                    Latitude  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2012-03-05 11:54:37   Unknown   \n",
      "                            0002               2012-03-06 08:35:09   Unknown   \n",
      "                            0003               2012-03-08 09:03:01   Unknown   \n",
      "                            0004               2012-03-09 11:42:31   Unknown   \n",
      "                            0005               2012-03-12 10:34:24   Unknown   \n",
      "                            0006               2012-03-13 08:45:29   Unknown   \n",
      "                            0007               2012-03-14 08:45:26   Unknown   \n",
      "                            0008               2012-03-16 08:56:43   Unknown   \n",
      "                            0009               2012-03-21 08:17:42   Unknown   \n",
      "                            0023               2012-03-22 10:34:40   Unknown   \n",
      "                            0024               2012-03-22 11:13:34   Unknown   \n",
      "                            0025               2012-03-22 11:16:26   Unknown   \n",
      "                            0026               2012-03-22 11:23:39   Unknown   \n",
      "                            0027               2012-03-22 11:27:07   Unknown   \n",
      "                            0028               2012-03-22 11:29:07   Unknown   \n",
      "                            0029               2012-03-22 12:00:12   Unknown   \n",
      "                            0030               2012-03-22 12:02:57   Unknown   \n",
      "                            0031               2012-03-22 12:17:44   Unknown   \n",
      "                            0244               2020-03-11 13:50:24   Unknown   \n",
      "\n",
      "                                                                    Longitude  \n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2012-03-05 11:54:37    Unknown  \n",
      "                            0002               2012-03-06 08:35:09    Unknown  \n",
      "                            0003               2012-03-08 09:03:01    Unknown  \n",
      "                            0004               2012-03-09 11:42:31    Unknown  \n",
      "                            0005               2012-03-12 10:34:24    Unknown  \n",
      "                            0006               2012-03-13 08:45:29    Unknown  \n",
      "                            0007               2012-03-14 08:45:26    Unknown  \n",
      "                            0008               2012-03-16 08:56:43    Unknown  \n",
      "                            0009               2012-03-21 08:17:42    Unknown  \n",
      "                            0023               2012-03-22 10:34:40    Unknown  \n",
      "                            0024               2012-03-22 11:13:34    Unknown  \n",
      "                            0025               2012-03-22 11:16:26    Unknown  \n",
      "                            0026               2012-03-22 11:23:39    Unknown  \n",
      "                            0027               2012-03-22 11:27:07    Unknown  \n",
      "                            0028               2012-03-22 11:29:07    Unknown  \n",
      "                            0029               2012-03-22 12:00:12    Unknown  \n",
      "                            0030               2012-03-22 12:02:57    Unknown  \n",
      "                            0031               2012-03-22 12:17:44    Unknown  \n",
      "                            0244               2020-03-11 13:50:24    Unknown  \n",
      "Length of incomplete data: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Numer of files: \", len(filename_list))\n",
    "print(\"Length of DF: \", results_df.shape[0])\n",
    "# check if some rows has no raw or csv file, if yes, print it out.\n",
    "incomplete_data = findIncompleteData(results=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length matches.\n",
      "Fn raw: 1679\n",
      "Total: 1679\n",
      "Dummy: 18\n",
      "Files [csv && raw]: 821\n",
      "Files [csv // raw]: 19\n"
     ]
    }
   ],
   "source": [
    "# check lengths\n",
    "checking = checkFileLength(len_fn_raw=len(afterEQ_fn),len_dummy=dummy_count,len_results=len(results_df),len_single=len(incomplete_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved, at ./output/\n"
     ]
    }
   ],
   "source": [
    "# save df to csv\n",
    "if checking:\n",
    "    save_path = \"./output/\"\n",
    "    results_df.to_csv(f'{save_path}CTD_震災後_{year}.csv')\n",
    "    print(f\"Saved, at {save_path}\")\n",
    "else:\n",
    "    print(\"No save -> length did not match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: (ing) compile 被災したPCより吸い出せたもの compactCTD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO list up all .csv // .raw files in the subdirectory\n",
    "# make two outputs: 1) csv, 2) raw\n",
    "# note: same pattern as afterEQ (becoz they are compactCTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 3419\n",
      "CSV length: 726\n",
      "RAW length: 2690\n",
      "Other length: 3\n",
      "Other files: ['20091002_082231_SNo_103_BlkNo_0072.RAW\\u3000七戻', '20091002_085758_SNo_103_BlkNo_0073.RAW\\u3000鵜住居', '20091002_091112_SNo_103_BlkNo_0074.RAW 大槌港']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def listupAllFiles():\n",
    "    def list_files(directory):\n",
    "        file_list = []\n",
    "        # Walk through all directories and subdirectories\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # Iterate over each file in the current directory\n",
    "            for file in files:\n",
    "                # Get the absolute path of the file -> get file only\n",
    "                #file_path = os.path.join(root, file)\n",
    "                file_path = file\n",
    "                # Append the file path to the list\n",
    "                file_list.append(file_path)\n",
    "        return file_list\n",
    "    \n",
    "    def showStats(all_files):\n",
    "        # count all length\n",
    "        print(f\"Length: {len(all_files)}\")\n",
    "        # count csv length\n",
    "        csv_count = sum(1 for file in all_files if file.lower().endswith((\".csv\", \".CSV\")))\n",
    "        print(f\"CSV length: {csv_count}\")\n",
    "        # count raw length\n",
    "        raw_count = sum(1 for file in all_files if file.lower().endswith((\".RAW\", \".raw\")))\n",
    "        print(f\"RAW length: {raw_count}\")\n",
    "        # check not csv nor raw\n",
    "        other_files = [file for file in all_files if not file.lower().endswith((\".csv\",\".raw\"))]\n",
    "        print(f\"Other length: {len(other_files)}\")\n",
    "        print(f\"Other files: {other_files}\")\n",
    "        \n",
    "    # Directory to search in\n",
    "    dir_name = \"CompactCTD data（被災したPCより吸い出せたもの）\"\n",
    "    directory = f\"../data/{dir_name}\"\n",
    "    # Get list of all files in directory and subdirectories\n",
    "    all_files = list_files(directory)\n",
    "    showStats(all_files)\n",
    "    # Save the list of files to a text file\n",
    "    np.savetxt(f'all_files_{dir_name}.txt', all_files, fmt='%s')\n",
    "    return all_files\n",
    "\n",
    "# run\n",
    "filename_list = listupAllFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files matched: 3380\n",
      "Number of files NOT matched: 39\n",
      "Pattern to be used: ^(?P<date>\\d{8})_(?P<time>\\d{6})_SNo_(?P<sno>\\d{3})_BlkNo_(?P<blkno>\\d{4})\\.(?P<filetype>[a-zA-Z]+)$\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def checkFilesAndPattern(all_files,pattern,show_not_matched=False):\n",
    "    re_pattern = re.compile(pattern)\n",
    "    matched_files = [file_name for file_name in all_files if re_pattern.match(file_name)]\n",
    "    # show length\n",
    "    print(f\"Number of files matched: {len(matched_files)}\")\n",
    "    not_matched_files = [file_name for file_name in all_files if not re_pattern.match(file_name)]\n",
    "    # show not matched\n",
    "    print(f\"Number of files NOT matched: {len(not_matched_files)}\")\n",
    "    if show_not_matched:\n",
    "        # show NOT matched files\n",
    "        print(f\"Files NOT matched: {not_matched_files}\")\n",
    "    return matched_files\n",
    "\n",
    "# run\n",
    "matched_files = checkFilesAndPattern(all_files=filename_list,pattern=pattern_afterEQ,show_not_matched=False)\n",
    "print(f\"Pattern to be used: {pattern_afterEQ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 431 files appeared more than twice.\n",
      "Extra 1082 should be considered (aka dummy files)\n",
      "Total 3380 (including redundant files)\n"
     ]
    }
   ],
   "source": [
    "# check if files are redundant\n",
    "from collections import Counter\n",
    "\n",
    "def checkFilesRedundent(all_files):\n",
    "    file_name_counter = Counter(all_files)\n",
    "    #  Check if any filename appears more than twice\n",
    "    n = 0\n",
    "    total_repeated = 0\n",
    "    total = 0\n",
    "    for file_name, count in file_name_counter.items():\n",
    "        total += count\n",
    "        if count >= 2:\n",
    "            #print(f\"{file_name} appears more than twice.\")\n",
    "            total_repeated += count - 1\n",
    "            n += 1\n",
    "    print(f\"Total {n} files appeared more than twice.\")\n",
    "    print(f\"Extra {total_repeated} should be considered (aka dummy files)\")\n",
    "    print(f\"Total {total} (including redundant files)\")\n",
    "    return n, total_repeated\n",
    "# run\n",
    "repeated_file_n, dummy_n = checkFilesRedundent(all_files=matched_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only handle matched files\n",
    "filename_list = matched_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TCDKU' '103' '0002' ... None None None]\n",
      " ['TCDKU' '103' '0001' ... None None None]\n",
      " ['TCDKU' '103' '0001' ... None None None]\n",
      " ...\n",
      " ['TCDKU' '103' '0003' ... None None None]\n",
      " ['TCDKU' '103' '0013' ... None None None]\n",
      " ['TCDKU' '103' '0014' ... None None None]]\n",
      "(3380, 9)\n"
     ]
    }
   ],
   "source": [
    "# Loop and stack all parsed file names\n",
    "results = loopAndStack(fn_list=filename_list, date_form=\"2\",pattern=pattern_afterEQ)\n",
    "print(results)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that the DF below is sorted by SondeNumber!\n",
      "                                                                     raw  csv  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime             \n",
      "TCDKU     103               0001               2006-11-19 23:50:24     1    0   \n",
      "                                               2007-04-04 15:58:55     1    0   \n",
      "                                               2007-05-08 08:49:26     1    1   \n",
      "                                               2007-05-22 08:25:08     1    1   \n",
      "                                               2007-05-29 08:38:36     2    1   \n",
      "...                                                                  ...  ...   \n",
      "                            0292               2009-12-03 09:58:32     1    0   \n",
      "                            0293               2009-12-07 08:24:48     1    1   \n",
      "                            0294               2009-12-07 08:48:30     1    1   \n",
      "                            0295               2009-12-07 08:59:33     1    1   \n",
      "                            0296               2009-12-07 09:50:59     1    0   \n",
      "\n",
      "                                                                    Latitude  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2006-11-19 23:50:24   Unknown   \n",
      "                                               2007-04-04 15:58:55   Unknown   \n",
      "                                               2007-05-08 08:49:26   Unknown   \n",
      "                                               2007-05-22 08:25:08   Unknown   \n",
      "                                               2007-05-29 08:38:36   Unknown   \n",
      "...                                                                      ...   \n",
      "                            0292               2009-12-03 09:58:32   Unknown   \n",
      "                            0293               2009-12-07 08:24:48   Unknown   \n",
      "                            0294               2009-12-07 08:48:30   Unknown   \n",
      "                            0295               2009-12-07 08:59:33   Unknown   \n",
      "                            0296               2009-12-07 09:50:59   Unknown   \n",
      "\n",
      "                                                                    Longitude  \n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2006-11-19 23:50:24    Unknown  \n",
      "                                               2007-04-04 15:58:55    Unknown  \n",
      "                                               2007-05-08 08:49:26    Unknown  \n",
      "                                               2007-05-22 08:25:08    Unknown  \n",
      "                                               2007-05-29 08:38:36    Unknown  \n",
      "...                                                                       ...  \n",
      "                            0292               2009-12-03 09:58:32    Unknown  \n",
      "                            0293               2009-12-07 08:24:48    Unknown  \n",
      "                            0294               2009-12-07 08:48:30    Unknown  \n",
      "                            0295               2009-12-07 08:59:33    Unknown  \n",
      "                            0296               2009-12-07 09:50:59    Unknown  \n",
      "\n",
      "[1527 rows x 4 columns]\n",
      "(1527, 4)\n"
     ]
    }
   ],
   "source": [
    "# Merge stacked list and change to pd.DataFrame\n",
    "print(\"Note that the DF below is sorted by SondeNumber!\")\n",
    "results_df = mergeStackedList(results,col_names=['SondeName','SerialNumber(Sno)','BlockNumber(Blkno)','StartDate','StartTime','raw','csv','Latitude','Longitude'],\n",
    "                             groupby=['SondeName','SerialNumber(Sno)','BlockNumber(Blkno)','StartDate','StartTime'])\n",
    "\n",
    "# Lat lon are unknown\n",
    "results_df.Latitude = 'Unknown'\n",
    "results_df.Longitude = 'Unknown'\n",
    "print(results_df)\n",
    "print(results_df.shape) # note: from 3380 to 1527 (830 are singular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of files:  3380\n",
      "Length of DF:  1527\n",
      "                                                                     raw  csv  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime             \n",
      "TCDKU     103               0001               2006-11-19 23:50:24     1    0   \n",
      "                                               2007-04-04 15:58:55     1    0   \n",
      "                                               2007-07-13 13:31:52     1    0   \n",
      "                                               2007-08-19 09:25:30     1    0   \n",
      "                                               2007-11-08 15:58:22     1    0   \n",
      "...                                                                  ...  ...   \n",
      "                            0289               2009-11-30 09:38:43     1    0   \n",
      "                            0290               2009-12-01 11:32:44     1    0   \n",
      "                            0291               2009-12-02 10:00:02     1    0   \n",
      "                            0292               2009-12-03 09:58:32     1    0   \n",
      "                            0296               2009-12-07 09:50:59     1    0   \n",
      "\n",
      "                                                                    Latitude  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2006-11-19 23:50:24   Unknown   \n",
      "                                               2007-04-04 15:58:55   Unknown   \n",
      "                                               2007-07-13 13:31:52   Unknown   \n",
      "                                               2007-08-19 09:25:30   Unknown   \n",
      "                                               2007-11-08 15:58:22   Unknown   \n",
      "...                                                                      ...   \n",
      "                            0289               2009-11-30 09:38:43   Unknown   \n",
      "                            0290               2009-12-01 11:32:44   Unknown   \n",
      "                            0291               2009-12-02 10:00:02   Unknown   \n",
      "                            0292               2009-12-03 09:58:32   Unknown   \n",
      "                            0296               2009-12-07 09:50:59   Unknown   \n",
      "\n",
      "                                                                    Longitude  \n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2006-11-19 23:50:24    Unknown  \n",
      "                                               2007-04-04 15:58:55    Unknown  \n",
      "                                               2007-07-13 13:31:52    Unknown  \n",
      "                                               2007-08-19 09:25:30    Unknown  \n",
      "                                               2007-11-08 15:58:22    Unknown  \n",
      "...                                                                       ...  \n",
      "                            0289               2009-11-30 09:38:43    Unknown  \n",
      "                            0290               2009-12-01 11:32:44    Unknown  \n",
      "                            0291               2009-12-02 10:00:02    Unknown  \n",
      "                            0292               2009-12-03 09:58:32    Unknown  \n",
      "                            0296               2009-12-07 09:50:59    Unknown  \n",
      "\n",
      "[830 rows x 4 columns]\n",
      "Length of incomplete data: 830\n"
     ]
    }
   ],
   "source": [
    "print(\"Numer of files: \", len(filename_list))\n",
    "print(\"Length of DF: \", results_df.shape[0])\n",
    "# check if some rows has no raw or csv file, if yes, print it out.\n",
    "incomplete_data = findIncompleteData(results=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length does not match!!\n",
      "Fn raw: 3380\n",
      "Total: 3306\n",
      "Dummy: 1082\n",
      "Files [csv && raw]: 697\n",
      "Files [csv // raw]: 830\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "TODO: raw matched files are 3380, but output is 3306\n"
     ]
    }
   ],
   "source": [
    "# check lengths\n",
    "dummy_count = dummy_n\n",
    "checking = checkFileLength(len_fn_raw=len(matched_files),len_dummy=dummy_count,len_results=len(results_df),len_single=len(incomplete_data))\n",
    "# TODO: raw matched files are 3380, but output is 3306, why? -> what happended in mergeStackedList() step?\n",
    "print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "print(\"TODO: raw matched files are 3380, but output is 3306\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2603 703 3306\n",
      "                                                                     raw  csv  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime             \n",
      "TCDKU     103               0001               2009-07-15 08:46:26     6    0   \n",
      "                            0002               2009-07-20 10:55:50     6    0   \n",
      "                            0003               2009-07-20 11:10:25     6    0   \n",
      "                            0004               2009-07-20 14:51:01     6    0   \n",
      "                            0005               2009-07-21 14:08:00     6    0   \n",
      "...                                                                  ...  ...   \n",
      "                            0261               2009-11-10 09:21:45     4    1   \n",
      "                            0262               2009-11-10 09:36:30     4    1   \n",
      "                            0263               2009-11-10 09:45:48     4    0   \n",
      "                            0264               2009-11-11 09:45:03     3    1   \n",
      "                            0265               2009-11-11 09:54:21     3    0   \n",
      "\n",
      "                                                                    Latitude  \\\n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2009-07-15 08:46:26   Unknown   \n",
      "                            0002               2009-07-20 10:55:50   Unknown   \n",
      "                            0003               2009-07-20 11:10:25   Unknown   \n",
      "                            0004               2009-07-20 14:51:01   Unknown   \n",
      "                            0005               2009-07-21 14:08:00   Unknown   \n",
      "...                                                                      ...   \n",
      "                            0261               2009-11-10 09:21:45   Unknown   \n",
      "                            0262               2009-11-10 09:36:30   Unknown   \n",
      "                            0263               2009-11-10 09:45:48   Unknown   \n",
      "                            0264               2009-11-11 09:45:03   Unknown   \n",
      "                            0265               2009-11-11 09:54:21   Unknown   \n",
      "\n",
      "                                                                    Longitude  \n",
      "SondeName SerialNumber(Sno) BlockNumber(Blkno) StartDate  StartTime            \n",
      "TCDKU     103               0001               2009-07-15 08:46:26    Unknown  \n",
      "                            0002               2009-07-20 10:55:50    Unknown  \n",
      "                            0003               2009-07-20 11:10:25    Unknown  \n",
      "                            0004               2009-07-20 14:51:01    Unknown  \n",
      "                            0005               2009-07-21 14:08:00    Unknown  \n",
      "...                                                                       ...  \n",
      "                            0261               2009-11-10 09:21:45    Unknown  \n",
      "                            0262               2009-11-10 09:36:30    Unknown  \n",
      "                            0263               2009-11-10 09:45:48    Unknown  \n",
      "                            0264               2009-11-11 09:45:03    Unknown  \n",
      "                            0265               2009-11-11 09:54:21    Unknown  \n",
      "\n",
      "[265 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# check length by sum up raw and csv\n",
    "raw_sum = np.sum(results_df[\"raw\"])\n",
    "csv_sum = np.sum(results_df[\"csv\"])\n",
    "print(raw_sum,csv_sum,raw_sum+csv_sum)\n",
    "print(results_df[results_df['raw']>2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved, at ./output/\n"
     ]
    }
   ],
   "source": [
    "# save df to csv\n",
    "#if checking:\n",
    "#    save_path = \"./output/\"\n",
    "#    results_df.to_csv(f'{save_path}CTD_被災したPCより吸い出せたもの_{year}.csv')\n",
    "#    print(f\"Saved, at {save_path}\")\n",
    "#else:\n",
    "#    print(\"No save -> length did not match.\")\n",
    "\n",
    "save_path = \"./output/\"\n",
    "results_df.to_csv(f'{save_path}CTD_被災したPCより吸い出せたもの_all.csv')\n",
    "print(f\"Saved, at {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "End of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
